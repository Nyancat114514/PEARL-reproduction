2024-03-30 15:51:22,644 [trainer.py] => config: configs/mimg10_inflora.json
2024-03-30 15:51:22,644 [trainer.py] => device: [device(type='cuda', index=0)]
2024-03-30 15:51:22,644 [trainer.py] => prefix: reproduce
2024-03-30 15:51:22,644 [trainer.py] => dataset: ImageNet_R
2024-03-30 15:51:22,644 [trainer.py] => data_path: data/imagenet-r
2024-03-30 15:51:22,644 [trainer.py] => memory_size: 0
2024-03-30 15:51:22,644 [trainer.py] => memory_per_class: 0
2024-03-30 15:51:22,644 [trainer.py] => fixed_memory: True
2024-03-30 15:51:22,644 [trainer.py] => shuffle: False
2024-03-30 15:51:22,644 [trainer.py] => init_cls: 20
2024-03-30 15:51:22,644 [trainer.py] => increment: 20
2024-03-30 15:51:22,644 [trainer.py] => model_name: InfLoRA
2024-03-30 15:51:22,644 [trainer.py] => net_type: sip
2024-03-30 15:51:22,644 [trainer.py] => embd_dim: 768
2024-03-30 15:51:22,644 [trainer.py] => num_heads: 12
2024-03-30 15:51:22,644 [trainer.py] => total_sessions: 10
2024-03-30 15:51:22,644 [trainer.py] => seed: 0
2024-03-30 15:51:22,644 [trainer.py] => EPSILON: 1e-08
2024-03-30 15:51:22,644 [trainer.py] => init_epoch: 50
2024-03-30 15:51:22,644 [trainer.py] => optim: adam
2024-03-30 15:51:22,644 [trainer.py] => init_lr: 0.0005
2024-03-30 15:51:22,644 [trainer.py] => init_lr_decay: 0.1
2024-03-30 15:51:22,644 [trainer.py] => init_weight_decay: 0.0
2024-03-30 15:51:22,645 [trainer.py] => epochs: 50
2024-03-30 15:51:22,645 [trainer.py] => lrate: 0.0005
2024-03-30 15:51:22,645 [trainer.py] => lrate_decay: 0.1
2024-03-30 15:51:22,645 [trainer.py] => batch_size: 128
2024-03-30 15:51:22,645 [trainer.py] => weight_decay: 0.0
2024-03-30 15:51:22,645 [trainer.py] => rank: 10
2024-03-30 15:51:22,645 [trainer.py] => lamb: 0.98
2024-03-30 15:51:22,645 [trainer.py] => lame: 1.0
2024-03-30 15:51:22,645 [trainer.py] => num_workers: 16
2024-03-30 15:51:22,733 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-30 15:51:25,860 [trainer.py] => All params: 111348451
2024-03-30 15:51:25,862 [trainer.py] => Trainable params: 111348451
2024-03-30 15:51:25,862 [inflora.py] => Learning on 0-20
2024-03-30 16:08:58,654 [inflora.py] => Task 0, Epoch 50/50 => Loss 0.145, Train_accy 95.46
2024-03-30 16:09:13,621 [inflora.py] => Layer 1 : 7/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 2 : 11/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 3 : 15/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 4 : 18/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 5 : 29/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 6 : 31/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 7 : 37/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 8 : 40/768
2024-03-30 16:09:13,622 [inflora.py] => Layer 9 : 61/768
2024-03-30 16:09:13,623 [inflora.py] => Layer 10 : 74/768
2024-03-30 16:09:13,623 [inflora.py] => Layer 11 : 34/768
2024-03-30 16:09:13,623 [inflora.py] => Layer 12 : 70/768
2024-03-30 16:09:13,645 [trainer.py] => Time:1067.7823977470398
2024-03-30 16:09:19,755 [trainer.py] => Time:6.1104185581207275
2024-03-30 16:09:19,756 [inflora.py] => Exemplar size: 0
2024-03-30 16:09:19,756 [trainer.py] => CNN: {'total': 91.55, '00-19': 91.55, 'old': 0, 'new': 91.55}
2024-03-30 16:09:19,756 [trainer.py] => CNN top1 curve: [91.55]
2024-03-30 16:09:19,756 [trainer.py] => CNN top1 with task curve: [91.55]
2024-03-30 16:09:19,756 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-30 16:09:19,764 [trainer.py] => All params: 111348451
2024-03-30 16:09:19,767 [trainer.py] => Trainable params: 199700
2024-03-30 16:09:19,767 [inflora.py] => Learning on 20-40
2024-03-30 16:29:27,316 [inflora.py] => Task 1, Epoch 50/50 => Loss 0.158, Train_accy 95.34
2024-03-30 16:29:46,133 [inflora.py] => Layer 1 : 8/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 2 : 14/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 3 : 20/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 4 : 28/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 5 : 41/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 6 : 40/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 7 : 49/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 8 : 52/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 9 : 77/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 10 : 94/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 11 : 48/768
2024-03-30 16:29:46,134 [inflora.py] => Layer 12 : 130/768
2024-03-30 16:29:46,168 [trainer.py] => Time:1226.4010112285614
2024-03-30 16:29:54,198 [trainer.py] => Time:8.030128955841064
2024-03-30 16:29:54,199 [inflora.py] => Exemplar size: 0
2024-03-30 16:29:54,199 [trainer.py] => CNN: {'total': 87.73, '00-19': 87.39, '20-39': 88.08, 'old': 87.39, 'new': 88.08}
2024-03-30 16:29:54,199 [trainer.py] => CNN top1 curve: [91.55, 87.73]
2024-03-30 16:29:54,199 [trainer.py] => CNN top1 with task curve: [91.55, 91.13]
2024-03-30 16:29:54,199 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358]
2024-03-30 16:29:54,201 [trainer.py] => All params: 111348451
2024-03-30 16:29:54,203 [trainer.py] => Trainable params: 199700
2024-03-30 16:29:54,203 [inflora.py] => Learning on 40-60
2024-03-30 16:42:32,301 [inflora.py] => Task 2, Epoch 50/50 => Loss 0.201, Train_accy 94.72
2024-03-30 16:43:05,613 [inflora.py] => Layer 1 : 8/768
2024-03-30 16:43:05,613 [inflora.py] => Layer 2 : 15/768
2024-03-30 16:43:05,613 [inflora.py] => Layer 3 : 25/768
2024-03-30 16:43:05,613 [inflora.py] => Layer 4 : 36/768
2024-03-30 16:43:05,614 [inflora.py] => Layer 5 : 50/768
2024-03-30 16:43:05,617 [inflora.py] => Layer 6 : 51/768
2024-03-30 16:43:05,618 [inflora.py] => Layer 7 : 64/768
2024-03-30 16:43:05,618 [inflora.py] => Layer 8 : 69/768
2024-03-30 16:43:05,618 [inflora.py] => Layer 9 : 100/768
2024-03-30 16:43:05,618 [inflora.py] => Layer 10 : 113/768
2024-03-30 16:43:05,618 [inflora.py] => Layer 11 : 71/768
2024-03-30 16:43:05,618 [inflora.py] => Layer 12 : 149/768
2024-03-30 16:43:05,705 [trainer.py] => Time:791.5019361972809
2024-03-30 16:43:14,443 [trainer.py] => Time:8.738489151000977
2024-03-30 16:43:14,444 [inflora.py] => Exemplar size: 0
2024-03-30 16:43:14,444 [trainer.py] => CNN: {'total': 83.01, '00-19': 82.95, '20-39': 85.9, '40-59': 78.52, 'old': 84.42, 'new': 78.52}
2024-03-30 16:43:14,444 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01]
2024-03-30 16:43:14,444 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96]
2024-03-30 16:43:14,444 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418]
2024-03-30 16:43:14,447 [trainer.py] => All params: 111348451
2024-03-30 16:43:14,449 [trainer.py] => Trainable params: 199700
2024-03-30 16:43:14,449 [inflora.py] => Learning on 60-80
2024-03-30 16:59:59,352 [inflora.py] => Task 3, Epoch 50/50 => Loss 0.168, Train_accy 95.27
2024-03-30 17:00:21,476 [inflora.py] => Layer 1 : 8/768
2024-03-30 17:00:21,476 [inflora.py] => Layer 2 : 17/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 3 : 31/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 4 : 45/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 5 : 62/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 6 : 64/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 7 : 82/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 8 : 90/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 9 : 129/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 10 : 143/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 11 : 95/768
2024-03-30 17:00:21,477 [inflora.py] => Layer 12 : 179/768
2024-03-30 17:00:21,584 [trainer.py] => Time:1027.13533949852
2024-03-30 17:00:35,554 [trainer.py] => Time:13.969815492630005
2024-03-30 17:00:35,555 [inflora.py] => Exemplar size: 0
2024-03-30 17:00:35,555 [trainer.py] => CNN: {'total': 80.6, '00-19': 80.95, '20-39': 79.8, '40-59': 77.6, '60-79': 83.48, 'old': 79.71, 'new': 83.48}
2024-03-30 17:00:35,555 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6]
2024-03-30 17:00:35,555 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57]
2024-03-30 17:00:35,555 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136]
2024-03-30 17:00:35,558 [trainer.py] => All params: 111348451
2024-03-30 17:00:35,561 [trainer.py] => Trainable params: 199700
2024-03-30 17:00:35,561 [inflora.py] => Learning on 80-100
2024-03-30 17:19:56,941 [inflora.py] => Task 4, Epoch 50/50 => Loss 0.165, Train_accy 95.28
2024-03-30 17:20:17,991 [inflora.py] => Layer 1 : 9/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 2 : 19/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 3 : 40/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 4 : 59/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 5 : 80/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 6 : 80/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 7 : 101/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 8 : 116/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 9 : 172/768
2024-03-30 17:20:17,992 [inflora.py] => Layer 10 : 203/768
2024-03-30 17:20:17,993 [inflora.py] => Layer 11 : 140/768
2024-03-30 17:20:17,993 [inflora.py] => Layer 12 : 267/768
2024-03-30 17:20:18,036 [trainer.py] => Time:1182.47545003891
2024-03-30 17:20:34,310 [trainer.py] => Time:16.27354073524475
2024-03-30 17:20:34,310 [inflora.py] => Exemplar size: 0
2024-03-30 17:20:34,310 [trainer.py] => CNN: {'total': 80.14, '00-19': 81.38, '20-39': 79.07, '40-59': 76.67, '60-79': 76.55, '80-99': 84.81, 'old': 78.72, 'new': 84.81}
2024-03-30 17:20:34,310 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6, 80.14]
2024-03-30 17:20:34,310 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57, 88.35]
2024-03-30 17:20:34,310 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136, 0.8541532517707663]
2024-03-30 17:20:34,313 [trainer.py] => All params: 111348451
2024-03-30 17:20:34,314 [trainer.py] => Trainable params: 199700
2024-03-30 17:20:34,314 [inflora.py] => Learning on 100-120
2024-03-30 17:36:12,576 [inflora.py] => Task 5, Epoch 50/50 => Loss 0.195, Train_accy 93.94
2024-03-30 17:37:02,296 [inflora.py] => Layer 1 : 10/768
2024-03-30 17:37:02,296 [inflora.py] => Layer 2 : 22/768
2024-03-30 17:37:02,296 [inflora.py] => Layer 3 : 50/768
2024-03-30 17:37:02,296 [inflora.py] => Layer 4 : 71/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 5 : 96/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 6 : 100/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 7 : 128/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 8 : 144/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 9 : 218/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 10 : 263/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 11 : 190/768
2024-03-30 17:37:02,297 [inflora.py] => Layer 12 : 346/768
2024-03-30 17:37:02,374 [trainer.py] => Time:988.0595870018005
2024-03-30 17:37:21,019 [trainer.py] => Time:18.644293308258057
2024-03-30 17:37:21,019 [inflora.py] => Exemplar size: 0
2024-03-30 17:37:21,019 [trainer.py] => CNN: {'total': 77.88, '00-19': 78.37, '20-39': 78.92, '40-59': 72.06, '60-79': 75.49, '80-99': 82.87, '100-119': 76.43, 'old': 78.14, 'new': 76.43}
2024-03-30 17:37:21,019 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6, 80.14, 77.88]
2024-03-30 17:37:21,019 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57, 88.35, 87.64]
2024-03-30 17:37:21,020 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136, 0.8541532517707663, 0.8308783415166394]
2024-03-30 17:37:21,024 [trainer.py] => All params: 111348451
2024-03-30 17:37:21,028 [trainer.py] => Trainable params: 199700
2024-03-30 17:37:21,028 [inflora.py] => Learning on 120-140
2024-03-30 17:52:53,922 [inflora.py] => Task 6, Epoch 50/50 => Loss 0.201, Train_accy 93.78
2024-03-30 17:53:11,722 [inflora.py] => Layer 1 : 10/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 2 : 25/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 3 : 60/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 4 : 88/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 5 : 115/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 6 : 123/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 7 : 157/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 8 : 181/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 9 : 277/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 10 : 342/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 11 : 267/768
2024-03-30 17:53:11,723 [inflora.py] => Layer 12 : 464/768
2024-03-30 17:53:11,769 [trainer.py] => Time:950.7411730289459
2024-03-30 17:53:32,081 [trainer.py] => Time:20.311407804489136
2024-03-30 17:53:32,081 [inflora.py] => Exemplar size: 0
2024-03-30 17:53:32,081 [trainer.py] => CNN: {'total': 74.86, '00-19': 75.5, '20-39': 76.74, '40-59': 71.82, '60-79': 72.47, '80-99': 77.07, '100-119': 73.57, '120-139': 74.96, 'old': 74.85, 'new': 74.96}
2024-03-30 17:53:32,081 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6, 80.14, 77.88, 74.86]
2024-03-30 17:53:32,081 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57, 88.35, 87.64, 85.51]
2024-03-30 17:53:32,081 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136, 0.8541532517707663, 0.8308783415166394, 0.7958656330749354]
2024-03-30 17:53:32,084 [trainer.py] => All params: 111348451
2024-03-30 17:53:32,087 [trainer.py] => Trainable params: 199700
2024-03-30 17:53:32,087 [inflora.py] => Learning on 140-160
2024-03-30 18:06:34,666 [inflora.py] => Task 7, Epoch 50/50 => Loss 0.225, Train_accy 93.20
2024-03-30 18:06:49,415 [inflora.py] => Layer 1 : 11/768
2024-03-30 18:06:49,415 [inflora.py] => Layer 2 : 29/768
2024-03-30 18:06:49,415 [inflora.py] => Layer 3 : 70/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 4 : 104/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 5 : 133/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 6 : 141/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 7 : 181/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 8 : 214/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 9 : 318/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 10 : 381/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 11 : 315/768
2024-03-30 18:06:49,416 [inflora.py] => Layer 12 : 493/768
2024-03-30 18:06:49,462 [trainer.py] => Time:797.3749048709869
2024-03-30 18:07:11,392 [trainer.py] => Time:21.929739952087402
2024-03-30 18:07:11,392 [inflora.py] => Exemplar size: 0
2024-03-30 18:07:11,392 [trainer.py] => CNN: {'total': 72.99, '00-19': 75.07, '20-39': 76.02, '40-59': 68.82, '60-79': 68.92, '80-99': 75.28, '100-119': 72.5, '120-139': 72.76, '140-159': 71.39, 'old': 73.15, 'new': 71.39}
2024-03-30 18:07:11,392 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6, 80.14, 77.88, 74.86, 72.99]
2024-03-30 18:07:11,392 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57, 88.35, 87.64, 85.51, 85.32]
2024-03-30 18:07:11,392 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136, 0.8541532517707663, 0.8308783415166394, 0.7958656330749354, 0.7805555555555556]
2024-03-30 18:07:11,395 [trainer.py] => All params: 111348451
2024-03-30 18:07:11,400 [trainer.py] => Trainable params: 199700
2024-03-30 18:07:11,400 [inflora.py] => Learning on 160-180
2024-03-30 18:24:29,728 [inflora.py] => Task 8, Epoch 50/50 => Loss 0.137, Train_accy 95.90
2024-03-30 18:24:48,736 [inflora.py] => Layer 1 : 13/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 2 : 38/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 3 : 96/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 4 : 141/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 5 : 190/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 6 : 201/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 7 : 251/768
2024-03-30 18:24:48,737 [inflora.py] => Layer 8 : 296/768
2024-03-30 18:24:48,738 [inflora.py] => Layer 9 : 414/768
2024-03-30 18:24:48,738 [inflora.py] => Layer 10 : 483/768
2024-03-30 18:24:48,738 [inflora.py] => Layer 11 : 426/768
2024-03-30 18:24:48,738 [inflora.py] => Layer 12 : 559/768
2024-03-30 18:24:48,778 [trainer.py] => Time:1057.3785338401794
2024-03-30 18:25:17,840 [trainer.py] => Time:29.06124997138977
2024-03-30 18:25:17,840 [inflora.py] => Exemplar size: 0
2024-03-30 18:25:17,840 [trainer.py] => CNN: {'total': 72.95, '00-19': 75.21, '20-39': 73.69, '40-59': 68.59, '60-79': 68.74, '80-99': 75.28, '100-119': 69.82, '120-139': 69.37, '140-159': 70.45, '160-179': 81.64, 'old': 71.79, 'new': 81.64}
2024-03-30 18:25:17,840 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6, 80.14, 77.88, 74.86, 72.99, 72.95]
2024-03-30 18:25:17,840 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57, 88.35, 87.64, 85.51, 85.32, 85.59]
2024-03-30 18:25:17,840 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136, 0.8541532517707663, 0.8308783415166394, 0.7958656330749354, 0.7805555555555556, 0.7757026976042256]
2024-03-30 18:25:17,843 [trainer.py] => All params: 111348451
2024-03-30 18:25:17,845 [trainer.py] => Trainable params: 199700
2024-03-30 18:25:17,845 [inflora.py] => Learning on 180-200
2024-03-30 18:39:57,160 [inflora.py] => Task 9, Epoch 50/50 => Loss 0.205, Train_accy 94.29
2024-03-30 18:40:17,913 [inflora.py] => Layer 1 : 17/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 2 : 52/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 3 : 128/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 4 : 192/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 5 : 248/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 6 : 272/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 7 : 335/768
2024-03-30 18:40:17,914 [inflora.py] => Layer 8 : 392/768
2024-03-30 18:40:17,915 [inflora.py] => Layer 9 : 505/768
2024-03-30 18:40:17,915 [inflora.py] => Layer 10 : 572/768
2024-03-30 18:40:17,915 [inflora.py] => Layer 11 : 545/768
2024-03-30 18:40:17,915 [inflora.py] => Layer 12 : 644/768
2024-03-30 18:40:18,057 [trainer.py] => Time:900.211104631424
2024-03-30 18:40:32,605 [trainer.py] => Time:14.548079490661621
2024-03-30 18:40:32,605 [inflora.py] => Exemplar size: 0
2024-03-30 18:40:32,605 [trainer.py] => CNN: {'total': 73.07, '00-19': 74.36, '20-39': 74.13, '40-59': 69.28, '60-79': 69.63, '80-99': 74.03, '100-119': 69.64, '120-139': 68.7, '140-159': 68.56, '160-179': 80.52, '180-199': 77.4, 'old': 72.5, 'new': 77.4}
2024-03-30 18:40:32,605 [trainer.py] => CNN top1 curve: [91.55, 87.73, 83.01, 80.6, 80.14, 77.88, 74.86, 72.99, 72.95, 73.07]
2024-03-30 18:40:32,605 [trainer.py] => CNN top1 with task curve: [91.55, 91.13, 87.96, 87.57, 88.35, 87.64, 85.51, 85.32, 85.59, 85.4]
2024-03-30 18:40:32,606 [trainer.py] => CNN top1 task curve: [1.0, 0.9357864357864358, 0.9037932930181418, 0.8690176322418136, 0.8541532517707663, 0.8308783415166394, 0.7958656330749354, 0.7805555555555556, 0.7757026976042256, 0.7703333333333333]
2024-03-30 19:03:46,365 [trainer.py] => config: configs/mimg10_inflora.json
2024-03-30 19:03:46,365 [trainer.py] => device: [device(type='cuda', index=0)]
2024-03-30 19:03:46,365 [trainer.py] => prefix: reproduce
2024-03-30 19:03:46,365 [trainer.py] => dataset: ImageNet_R
2024-03-30 19:03:46,365 [trainer.py] => data_path: data/imagenet-r
2024-03-30 19:03:46,365 [trainer.py] => memory_size: 0
2024-03-30 19:03:46,365 [trainer.py] => memory_per_class: 0
2024-03-30 19:03:46,365 [trainer.py] => fixed_memory: True
2024-03-30 19:03:46,366 [trainer.py] => shuffle: False
2024-03-30 19:03:46,366 [trainer.py] => init_cls: 20
2024-03-30 19:03:46,366 [trainer.py] => increment: 20
2024-03-30 19:03:46,366 [trainer.py] => model_name: InfLoRA
2024-03-30 19:03:46,366 [trainer.py] => net_type: sip
2024-03-30 19:03:46,366 [trainer.py] => embd_dim: 768
2024-03-30 19:03:46,366 [trainer.py] => num_heads: 12
2024-03-30 19:03:46,366 [trainer.py] => total_sessions: 10
2024-03-30 19:03:46,366 [trainer.py] => seed: 0
2024-03-30 19:03:46,366 [trainer.py] => EPSILON: 1e-08
2024-03-30 19:03:46,366 [trainer.py] => init_epoch: 50
2024-03-30 19:03:46,366 [trainer.py] => optim: adam
2024-03-30 19:03:46,366 [trainer.py] => init_lr: 0.0005
2024-03-30 19:03:46,366 [trainer.py] => init_lr_decay: 0.1
2024-03-30 19:03:46,366 [trainer.py] => init_weight_decay: 0.0
2024-03-30 19:03:46,366 [trainer.py] => epochs: 50
2024-03-30 19:03:46,366 [trainer.py] => lrate: 0.0005
2024-03-30 19:03:46,366 [trainer.py] => lrate_decay: 0.1
2024-03-30 19:03:46,366 [trainer.py] => batch_size: 128
2024-03-30 19:03:46,366 [trainer.py] => weight_decay: 0.0
2024-03-30 19:03:46,366 [trainer.py] => rank: 10
2024-03-30 19:03:46,366 [trainer.py] => lamb: 0.98
2024-03-30 19:03:46,366 [trainer.py] => lame: 1.0
2024-03-30 19:03:46,366 [trainer.py] => num_workers: 16
2024-03-30 19:03:46,469 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-30 19:03:51,803 [trainer.py] => All params: 111348451
2024-03-30 19:03:51,807 [trainer.py] => Trainable params: 111348451
2024-03-30 19:03:51,807 [inflora.py] => Learning on 0-20
2024-03-30 19:21:52,733 [inflora.py] => Task 0, Epoch 50/50 => Loss 0.154, Train_accy 96.01
2024-03-30 19:22:18,187 [inflora.py] => Layer 1 : 7/768
2024-03-30 19:22:18,187 [inflora.py] => Layer 2 : 11/768
2024-03-30 19:22:18,187 [inflora.py] => Layer 3 : 14/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 4 : 19/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 5 : 28/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 6 : 26/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 7 : 30/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 8 : 31/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 9 : 50/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 10 : 60/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 11 : 28/768
2024-03-30 19:22:18,188 [inflora.py] => Layer 12 : 81/768
2024-03-30 19:22:18,271 [trainer.py] => Time:1106.464046239853
2024-03-30 19:22:22,909 [trainer.py] => Time:4.637161016464233
2024-03-30 19:22:22,909 [inflora.py] => Exemplar size: 0
2024-03-30 19:22:22,909 [trainer.py] => CNN: {'total': 91.4, '00-19': 91.4, 'old': 0, 'new': 91.4}
2024-03-30 19:22:22,910 [trainer.py] => CNN top1 curve: [91.4]
2024-03-30 19:22:22,910 [trainer.py] => CNN top1 with task curve: [91.4]
2024-03-30 19:22:22,910 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-30 19:22:22,912 [trainer.py] => All params: 111348451
2024-03-30 19:22:22,914 [trainer.py] => Trainable params: 199700
2024-03-30 19:22:22,914 [inflora.py] => Learning on 20-40
2024-03-30 19:42:48,842 [inflora.py] => Task 1, Epoch 50/50 => Loss 0.166, Train_accy 95.10
2024-03-30 19:43:08,635 [inflora.py] => Layer 1 : 8/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 2 : 13/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 3 : 17/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 4 : 23/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 5 : 37/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 6 : 32/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 7 : 37/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 8 : 40/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 9 : 65/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 10 : 79/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 11 : 40/768
2024-03-30 19:43:08,636 [inflora.py] => Layer 12 : 131/768
2024-03-30 19:43:08,668 [trainer.py] => Time:1245.7543878555298
2024-03-30 19:43:18,923 [trainer.py] => Time:10.253955364227295
2024-03-30 19:43:18,923 [inflora.py] => Exemplar size: 0
2024-03-30 19:43:18,923 [trainer.py] => CNN: {'total': 87.88, '00-19': 87.97, '20-39': 87.79, 'old': 87.97, 'new': 87.79}
2024-03-30 19:43:18,923 [trainer.py] => CNN top1 curve: [91.4, 87.88]
2024-03-30 19:43:18,923 [trainer.py] => CNN top1 with task curve: [91.4, 91.49]
2024-03-30 19:43:18,923 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336]
2024-03-30 19:43:18,926 [trainer.py] => All params: 111348451
2024-03-30 19:43:18,927 [trainer.py] => Trainable params: 199700
2024-03-30 19:43:18,927 [inflora.py] => Learning on 40-60
2024-03-30 19:55:33,862 [inflora.py] => Task 2, Epoch 50/50 => Loss 0.214, Train_accy 94.26
2024-03-30 19:55:50,619 [inflora.py] => Layer 1 : 8/768
2024-03-30 19:55:50,620 [inflora.py] => Layer 2 : 14/768
2024-03-30 19:55:50,620 [inflora.py] => Layer 3 : 20/768
2024-03-30 19:55:50,620 [inflora.py] => Layer 4 : 27/768
2024-03-30 19:55:50,620 [inflora.py] => Layer 5 : 45/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 6 : 42/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 7 : 50/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 8 : 53/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 9 : 85/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 10 : 97/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 11 : 62/768
2024-03-30 19:55:50,621 [inflora.py] => Layer 12 : 148/768
2024-03-30 19:55:50,790 [trainer.py] => Time:751.8627381324768
2024-03-30 19:55:59,735 [trainer.py] => Time:8.944352865219116
2024-03-30 19:55:59,735 [inflora.py] => Exemplar size: 0
2024-03-30 19:55:59,735 [trainer.py] => CNN: {'total': 84.28, '00-19': 86.39, '20-39': 86.34, '40-59': 77.6, 'old': 86.36, 'new': 77.6}
2024-03-30 19:55:59,735 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28]
2024-03-30 19:55:59,735 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29]
2024-03-30 19:55:59,735 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648]
2024-03-30 19:55:59,738 [trainer.py] => All params: 111348451
2024-03-30 19:55:59,740 [trainer.py] => Trainable params: 199700
2024-03-30 19:55:59,740 [inflora.py] => Learning on 60-80
2024-03-30 20:12:32,463 [inflora.py] => Task 3, Epoch 50/50 => Loss 0.174, Train_accy 94.85
2024-03-30 20:12:49,448 [inflora.py] => Layer 1 : 8/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 2 : 16/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 3 : 26/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 4 : 36/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 5 : 55/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 6 : 53/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 7 : 65/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 8 : 70/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 9 : 113/768
2024-03-30 20:12:49,449 [inflora.py] => Layer 10 : 128/768
2024-03-30 20:12:49,450 [inflora.py] => Layer 11 : 85/768
2024-03-30 20:12:49,450 [inflora.py] => Layer 12 : 181/768
2024-03-30 20:12:49,487 [trainer.py] => Time:1009.7474443912506
2024-03-30 20:13:02,272 [trainer.py] => Time:12.784487962722778
2024-03-30 20:13:02,272 [inflora.py] => Exemplar size: 0
2024-03-30 20:13:02,272 [trainer.py] => CNN: {'total': 81.19, '00-19': 81.66, '20-39': 81.1, '40-59': 79.45, '60-79': 82.06, 'old': 80.92, 'new': 82.06}
2024-03-30 20:13:02,272 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19]
2024-03-30 20:13:02,272 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29]
2024-03-30 20:13:02,272 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576]
2024-03-30 20:13:02,275 [trainer.py] => All params: 111348451
2024-03-30 20:13:02,276 [trainer.py] => Trainable params: 199700
2024-03-30 20:13:02,276 [inflora.py] => Learning on 80-100
2024-03-30 20:32:16,817 [inflora.py] => Task 4, Epoch 50/50 => Loss 0.175, Train_accy 94.85
2024-03-30 20:32:37,729 [inflora.py] => Layer 1 : 9/768
2024-03-30 20:32:37,730 [inflora.py] => Layer 2 : 18/768
2024-03-30 20:32:37,730 [inflora.py] => Layer 3 : 34/768
2024-03-30 20:32:37,730 [inflora.py] => Layer 4 : 47/768
2024-03-30 20:32:37,730 [inflora.py] => Layer 5 : 69/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 6 : 65/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 7 : 80/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 8 : 88/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 9 : 147/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 10 : 174/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 11 : 112/768
2024-03-30 20:32:37,731 [inflora.py] => Layer 12 : 267/768
2024-03-30 20:32:37,805 [trainer.py] => Time:1175.528384923935
2024-03-30 20:32:54,829 [trainer.py] => Time:17.02374792098999
2024-03-30 20:32:54,829 [inflora.py] => Exemplar size: 0
2024-03-30 20:32:54,829 [trainer.py] => CNN: {'total': 81.17, '00-19': 82.81, '20-39': 80.52, '40-59': 77.6, '60-79': 77.98, '80-99': 84.81, 'old': 80.06, 'new': 84.81}
2024-03-30 20:32:54,829 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19, 81.17]
2024-03-30 20:32:54,829 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29, 88.54]
2024-03-30 20:32:54,829 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576, 0.8670315518351578]
2024-03-30 20:32:54,832 [trainer.py] => All params: 111348451
2024-03-30 20:32:54,833 [trainer.py] => Trainable params: 199700
2024-03-30 20:32:54,833 [inflora.py] => Learning on 100-120
2024-03-30 20:48:23,830 [inflora.py] => Task 5, Epoch 50/50 => Loss 0.200, Train_accy 93.85
2024-03-30 20:48:42,439 [inflora.py] => Layer 1 : 10/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 2 : 21/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 3 : 40/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 4 : 56/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 5 : 82/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 6 : 82/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 7 : 100/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 8 : 111/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 9 : 190/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 10 : 239/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 11 : 166/768
2024-03-30 20:48:42,440 [inflora.py] => Layer 12 : 352/768
2024-03-30 20:48:42,478 [trainer.py] => Time:947.6446752548218
2024-03-30 20:49:01,424 [trainer.py] => Time:18.945303201675415
2024-03-30 20:49:01,424 [inflora.py] => Exemplar size: 0
2024-03-30 20:49:01,424 [trainer.py] => CNN: {'total': 79.92, '00-19': 80.66, '20-39': 82.27, '40-59': 75.29, '60-79': 77.09, '80-99': 82.6, '100-119': 79.11, 'old': 80.07, 'new': 79.11}
2024-03-30 20:49:01,424 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19, 81.17, 79.92]
2024-03-30 20:49:01,424 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29, 88.54, 88.65]
2024-03-30 20:49:01,424 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576, 0.8670315518351578, 0.8472449536279324]
2024-03-30 20:49:01,428 [trainer.py] => All params: 111348451
2024-03-30 20:49:01,431 [trainer.py] => Trainable params: 199700
2024-03-30 20:49:01,431 [inflora.py] => Learning on 120-140
2024-03-30 21:04:44,984 [inflora.py] => Task 6, Epoch 50/50 => Loss 0.206, Train_accy 93.74
2024-03-30 21:05:03,651 [inflora.py] => Layer 1 : 10/768
2024-03-30 21:05:03,652 [inflora.py] => Layer 2 : 24/768
2024-03-30 21:05:03,652 [inflora.py] => Layer 3 : 49/768
2024-03-30 21:05:03,652 [inflora.py] => Layer 4 : 70/768
2024-03-30 21:05:03,652 [inflora.py] => Layer 5 : 100/768
2024-03-30 21:05:03,652 [inflora.py] => Layer 6 : 104/768
2024-03-30 21:05:03,653 [inflora.py] => Layer 7 : 126/768
2024-03-30 21:05:03,653 [inflora.py] => Layer 8 : 146/768
2024-03-30 21:05:03,653 [inflora.py] => Layer 9 : 251/768
2024-03-30 21:05:03,653 [inflora.py] => Layer 10 : 327/768
2024-03-30 21:05:03,653 [inflora.py] => Layer 11 : 246/768
2024-03-30 21:05:03,653 [inflora.py] => Layer 12 : 469/768
2024-03-30 21:05:03,697 [trainer.py] => Time:962.2661302089691
2024-03-30 21:05:23,331 [trainer.py] => Time:19.633806467056274
2024-03-30 21:05:23,332 [inflora.py] => Exemplar size: 0
2024-03-30 21:05:23,332 [trainer.py] => CNN: {'total': 76.96, '00-19': 80.37, '20-39': 79.22, '40-59': 75.52, '60-79': 72.29, '80-99': 79.01, '100-119': 75.89, '120-139': 74.28, 'old': 77.39, 'new': 74.28}
2024-03-30 21:05:23,332 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19, 81.17, 79.92, 76.96]
2024-03-30 21:05:23,332 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29, 88.54, 88.65, 87.62]
2024-03-30 21:05:23,332 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576, 0.8670315518351578, 0.8472449536279324, 0.8160676532769556]
2024-03-30 21:05:23,338 [trainer.py] => All params: 111348451
2024-03-30 21:05:23,343 [trainer.py] => Trainable params: 199700
2024-03-30 21:05:23,344 [inflora.py] => Learning on 140-160
2024-03-30 21:18:52,715 [inflora.py] => Task 7, Epoch 50/50 => Loss 0.237, Train_accy 92.88
2024-03-30 21:19:09,996 [inflora.py] => Layer 1 : 11/768
2024-03-30 21:19:09,997 [inflora.py] => Layer 2 : 27/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 3 : 55/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 4 : 81/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 5 : 112/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 6 : 122/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 7 : 150/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 8 : 178/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 9 : 284/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 10 : 359/768
2024-03-30 21:19:09,998 [inflora.py] => Layer 11 : 281/768
2024-03-30 21:19:09,999 [inflora.py] => Layer 12 : 498/768
2024-03-30 21:19:10,056 [trainer.py] => Time:826.7120833396912
2024-03-30 21:19:36,547 [trainer.py] => Time:26.490996837615967
2024-03-30 21:19:36,548 [inflora.py] => Exemplar size: 0
2024-03-30 21:19:36,548 [trainer.py] => CNN: {'total': 75.17, '00-19': 79.23, '20-39': 78.05, '40-59': 71.82, '60-79': 69.45, '80-99': 77.35, '100-119': 75.18, '120-139': 73.43, '140-159': 73.52, 'old': 75.33, 'new': 73.52}
2024-03-30 21:19:36,548 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19, 81.17, 79.92, 76.96, 75.17]
2024-03-30 21:19:36,548 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29, 88.54, 88.65, 87.62, 86.69]
2024-03-30 21:19:36,548 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576, 0.8670315518351578, 0.8472449536279324, 0.8160676532769556, 0.7976495726495727]
2024-03-30 21:19:36,551 [trainer.py] => All params: 111348451
2024-03-30 21:19:36,554 [trainer.py] => Trainable params: 199700
2024-03-30 21:19:36,554 [inflora.py] => Learning on 160-180
2024-03-30 21:37:07,265 [inflora.py] => Task 8, Epoch 50/50 => Loss 0.129, Train_accy 96.30
2024-03-30 21:37:43,551 [inflora.py] => Layer 1 : 13/768
2024-03-30 21:37:43,552 [inflora.py] => Layer 2 : 37/768
2024-03-30 21:37:43,552 [inflora.py] => Layer 3 : 82/768
2024-03-30 21:37:43,552 [inflora.py] => Layer 4 : 119/768
2024-03-30 21:37:43,552 [inflora.py] => Layer 5 : 164/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 6 : 176/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 7 : 216/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 8 : 254/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 9 : 374/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 10 : 455/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 11 : 384/768
2024-03-30 21:37:43,553 [inflora.py] => Layer 12 : 557/768
2024-03-30 21:37:43,640 [trainer.py] => Time:1087.0866782665253
2024-03-30 21:38:12,655 [trainer.py] => Time:29.01430916786194
2024-03-30 21:38:12,656 [inflora.py] => Exemplar size: 0
2024-03-30 21:38:12,656 [trainer.py] => CNN: {'total': 75.8, '00-19': 78.94, '20-39': 79.22, '40-59': 70.67, '60-79': 70.69, '80-99': 77.21, '100-119': 74.64, '120-139': 71.24, '140-159': 71.87, '160-179': 83.09, 'old': 74.83, 'new': 83.09}
2024-03-30 21:38:12,656 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19, 81.17, 79.92, 76.96, 75.17, 75.8]
2024-03-30 21:38:12,656 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29, 88.54, 88.65, 87.62, 86.69, 87.19]
2024-03-30 21:38:12,656 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576, 0.8670315518351578, 0.8472449536279324, 0.8160676532769556, 0.7976495726495727, 0.797962648556876]
2024-03-30 21:38:12,659 [trainer.py] => All params: 111348451
2024-03-30 21:38:12,663 [trainer.py] => Trainable params: 199700
2024-03-30 21:38:12,663 [inflora.py] => Learning on 180-200
2024-03-30 21:53:51,119 [inflora.py] => Task 9, Epoch 50/50 => Loss 0.202, Train_accy 94.47
2024-03-30 21:54:57,224 [inflora.py] => Layer 1 : 17/768
2024-03-30 21:54:57,224 [inflora.py] => Layer 2 : 53/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 3 : 115/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 4 : 171/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 5 : 224/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 6 : 242/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 7 : 297/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 8 : 351/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 9 : 470/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 10 : 546/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 11 : 504/768
2024-03-30 21:54:57,225 [inflora.py] => Layer 12 : 640/768
2024-03-30 21:54:57,375 [trainer.py] => Time:1004.71204829216
2024-03-30 21:55:13,638 [trainer.py] => Time:16.263129472732544
2024-03-30 21:55:13,639 [inflora.py] => Exemplar size: 0
2024-03-30 21:55:13,639 [trainer.py] => CNN: {'total': 75.17, '00-19': 77.79, '20-39': 79.22, '40-59': 71.82, '60-79': 70.16, '80-99': 76.1, '100-119': 72.68, '120-139': 70.05, '140-159': 71.16, '160-179': 80.52, '180-199': 77.68, 'old': 74.83, 'new': 77.68}
2024-03-30 21:55:13,639 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.19, 81.17, 79.92, 76.96, 75.17, 75.8, 75.17]
2024-03-30 21:55:13,639 [trainer.py] => CNN top1 with task curve: [91.4, 91.49, 88.29, 88.29, 88.54, 88.65, 87.62, 86.69, 87.19, 87.12]
2024-03-30 21:55:13,639 [trainer.py] => CNN top1 task curve: [1.0, 0.9336219336219336, 0.9153380978559648, 0.873215785054576, 0.8670315518351578, 0.8472449536279324, 0.8160676532769556, 0.7976495726495727, 0.797962648556876, 0.7885]
2024-03-30 22:05:38,815 [trainer.py] => config: configs/mimg10_inflora.json
2024-03-30 22:05:38,815 [trainer.py] => device: [device(type='cuda', index=0)]
2024-03-30 22:05:38,815 [trainer.py] => prefix: reproduce
2024-03-30 22:05:38,815 [trainer.py] => dataset: ImageNet_R
2024-03-30 22:05:38,815 [trainer.py] => data_path: data/imagenet-r
2024-03-30 22:05:38,815 [trainer.py] => memory_size: 0
2024-03-30 22:05:38,815 [trainer.py] => memory_per_class: 0
2024-03-30 22:05:38,815 [trainer.py] => fixed_memory: True
2024-03-30 22:05:38,815 [trainer.py] => shuffle: False
2024-03-30 22:05:38,815 [trainer.py] => init_cls: 20
2024-03-30 22:05:38,816 [trainer.py] => increment: 20
2024-03-30 22:05:38,816 [trainer.py] => model_name: InfLoRA
2024-03-30 22:05:38,816 [trainer.py] => net_type: sip
2024-03-30 22:05:38,816 [trainer.py] => embd_dim: 768
2024-03-30 22:05:38,816 [trainer.py] => num_heads: 12
2024-03-30 22:05:38,816 [trainer.py] => total_sessions: 10
2024-03-30 22:05:38,816 [trainer.py] => seed: 0
2024-03-30 22:05:38,816 [trainer.py] => EPSILON: 1e-08
2024-03-30 22:05:38,816 [trainer.py] => init_epoch: 50
2024-03-30 22:05:38,816 [trainer.py] => optim: adam
2024-03-30 22:05:38,816 [trainer.py] => init_lr: 0.0005
2024-03-30 22:05:38,816 [trainer.py] => init_lr_decay: 0.1
2024-03-30 22:05:38,816 [trainer.py] => init_weight_decay: 0.0
2024-03-30 22:05:38,816 [trainer.py] => epochs: 50
2024-03-30 22:05:38,816 [trainer.py] => lrate: 0.0005
2024-03-30 22:05:38,816 [trainer.py] => lrate_decay: 0.1
2024-03-30 22:05:38,817 [trainer.py] => batch_size: 128
2024-03-30 22:05:38,817 [trainer.py] => weight_decay: 0.0
2024-03-30 22:05:38,817 [trainer.py] => rank: 10
2024-03-30 22:05:38,817 [trainer.py] => lamb: 0.98
2024-03-30 22:05:38,817 [trainer.py] => lame: 1.0
2024-03-30 22:05:38,817 [trainer.py] => num_workers: 16
2024-03-30 22:05:38,991 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-30 22:05:46,255 [trainer.py] => All params: 111348451
2024-03-30 22:05:46,263 [trainer.py] => Trainable params: 111348451
2024-03-30 22:05:46,265 [inflora.py] => Learning on 0-20
2024-03-30 22:07:28,198 [trainer.py] => config: configs/mimg10_inflora.json
2024-03-30 22:07:28,198 [trainer.py] => device: [device(type='cuda', index=3)]
2024-03-30 22:07:28,198 [trainer.py] => prefix: reproduce
2024-03-30 22:07:28,198 [trainer.py] => dataset: ImageNet_R
2024-03-30 22:07:28,198 [trainer.py] => data_path: data/imagenet-r
2024-03-30 22:07:28,198 [trainer.py] => memory_size: 0
2024-03-30 22:07:28,198 [trainer.py] => memory_per_class: 0
2024-03-30 22:07:28,198 [trainer.py] => fixed_memory: True
2024-03-30 22:07:28,199 [trainer.py] => shuffle: False
2024-03-30 22:07:28,199 [trainer.py] => init_cls: 20
2024-03-30 22:07:28,199 [trainer.py] => increment: 20
2024-03-30 22:07:28,199 [trainer.py] => model_name: InfLoRA
2024-03-30 22:07:28,199 [trainer.py] => net_type: sip
2024-03-30 22:07:28,199 [trainer.py] => embd_dim: 768
2024-03-30 22:07:28,199 [trainer.py] => num_heads: 12
2024-03-30 22:07:28,199 [trainer.py] => total_sessions: 10
2024-03-30 22:07:28,199 [trainer.py] => seed: 0
2024-03-30 22:07:28,199 [trainer.py] => EPSILON: 1e-08
2024-03-30 22:07:28,199 [trainer.py] => init_epoch: 50
2024-03-30 22:07:28,199 [trainer.py] => optim: adam
2024-03-30 22:07:28,199 [trainer.py] => init_lr: 0.0005
2024-03-30 22:07:28,199 [trainer.py] => init_lr_decay: 0.1
2024-03-30 22:07:28,200 [trainer.py] => init_weight_decay: 0.0
2024-03-30 22:07:28,200 [trainer.py] => epochs: 50
2024-03-30 22:07:28,200 [trainer.py] => lrate: 0.0005
2024-03-30 22:07:28,200 [trainer.py] => lrate_decay: 0.1
2024-03-30 22:07:28,200 [trainer.py] => batch_size: 128
2024-03-30 22:07:28,200 [trainer.py] => weight_decay: 0.0
2024-03-30 22:07:28,200 [trainer.py] => rank: 10
2024-03-30 22:07:28,200 [trainer.py] => lamb: 0.98
2024-03-30 22:07:28,200 [trainer.py] => lame: 1.0
2024-03-30 22:07:28,200 [trainer.py] => num_workers: 16
2024-03-30 22:07:28,353 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-30 22:07:35,836 [trainer.py] => All params: 111348451
2024-03-30 22:07:35,839 [trainer.py] => Trainable params: 111348451
2024-03-30 22:07:35,839 [inflora.py] => Learning on 0-20
2024-03-30 22:29:15,071 [inflora.py] => Task 0, Epoch 50/50 => Loss 0.154, Train_accy 96.01
2024-03-30 22:30:14,739 [inflora.py] => Layer 1 : 7/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 2 : 11/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 3 : 14/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 4 : 19/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 5 : 28/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 6 : 26/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 7 : 30/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 8 : 31/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 9 : 50/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 10 : 60/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 11 : 28/768
2024-03-30 22:30:14,740 [inflora.py] => Layer 12 : 81/768
2024-03-30 22:30:34,312 [trainer.py] => Time:1378.4727227687836
2024-03-30 22:30:42,528 [trainer.py] => Time:8.215404510498047
2024-03-30 22:30:42,528 [inflora.py] => Exemplar size: 0
2024-03-30 22:30:42,529 [trainer.py] => CNN: {'total': 91.4, '00-19': 91.4, 'old': 0, 'new': 91.4}
2024-03-30 22:30:42,529 [trainer.py] => CNN top1 curve: [91.4]
2024-03-30 22:30:42,529 [trainer.py] => CNN top1 with task curve: [91.4]
2024-03-30 22:30:42,529 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-30 22:30:42,533 [trainer.py] => All params: 111348451
2024-03-30 22:30:42,538 [trainer.py] => Trainable params: 199700
2024-03-30 22:30:42,539 [inflora.py] => Learning on 20-40
2024-03-30 22:55:27,739 [inflora.py] => Task 1, Epoch 50/50 => Loss 0.160, Train_accy 94.93
2024-03-30 22:56:36,439 [inflora.py] => Layer 1 : 8/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 2 : 14/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 3 : 19/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 4 : 25/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 5 : 39/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 6 : 33/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 7 : 38/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 8 : 40/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 9 : 67/768
2024-03-30 22:56:36,440 [inflora.py] => Layer 10 : 81/768
2024-03-30 22:56:36,441 [inflora.py] => Layer 11 : 40/768
2024-03-30 22:56:36,441 [inflora.py] => Layer 12 : 130/768
2024-03-30 22:56:57,938 [trainer.py] => Time:1575.398458480835
2024-03-30 22:57:09,404 [trainer.py] => Time:11.46530795097351
2024-03-30 22:57:09,404 [inflora.py] => Exemplar size: 0
2024-03-30 22:57:09,404 [trainer.py] => CNN: {'total': 87.88, '00-19': 87.97, '20-39': 87.79, 'old': 87.97, 'new': 87.79}
2024-03-30 22:57:09,404 [trainer.py] => CNN top1 curve: [91.4, 87.88]
2024-03-30 22:57:09,404 [trainer.py] => CNN top1 with task curve: [91.4, 91.13]
2024-03-30 22:57:09,404 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394]
2024-03-30 22:57:09,418 [trainer.py] => All params: 111348451
2024-03-30 22:57:09,421 [trainer.py] => Trainable params: 199700
2024-03-30 22:57:09,422 [inflora.py] => Learning on 40-60
2024-03-30 23:13:45,372 [inflora.py] => Task 2, Epoch 50/50 => Loss 0.196, Train_accy 94.66
2024-03-30 23:14:19,867 [inflora.py] => Layer 1 : 8/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 2 : 15/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 3 : 21/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 4 : 29/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 5 : 46/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 6 : 42/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 7 : 50/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 8 : 53/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 9 : 85/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 10 : 99/768
2024-03-30 23:14:19,868 [inflora.py] => Layer 11 : 62/768
2024-03-30 23:14:19,869 [inflora.py] => Layer 12 : 149/768
2024-03-30 23:14:28,599 [trainer.py] => Time:1039.1769046783447
2024-03-30 23:14:36,473 [trainer.py] => Time:7.874100208282471
2024-03-30 23:14:36,473 [inflora.py] => Exemplar size: 0
2024-03-30 23:14:36,473 [trainer.py] => CNN: {'total': 84.28, '00-19': 85.53, '20-39': 86.63, '40-59': 78.52, 'old': 86.08, 'new': 78.52}
2024-03-30 23:14:36,473 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28]
2024-03-30 23:14:36,473 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57]
2024-03-30 23:14:36,474 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901]
2024-03-30 23:14:36,476 [trainer.py] => All params: 111348451
2024-03-30 23:14:36,477 [trainer.py] => Trainable params: 199700
2024-03-30 23:14:36,478 [inflora.py] => Learning on 60-80
2024-03-30 23:28:16,310 [inflora.py] => Task 3, Epoch 50/50 => Loss 0.164, Train_accy 95.19
2024-03-30 23:28:33,135 [inflora.py] => Layer 1 : 8/768
2024-03-30 23:28:33,135 [inflora.py] => Layer 2 : 16/768
2024-03-30 23:28:33,135 [inflora.py] => Layer 3 : 27/768
2024-03-30 23:28:33,135 [inflora.py] => Layer 4 : 37/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 5 : 57/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 6 : 53/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 7 : 65/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 8 : 69/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 9 : 113/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 10 : 130/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 11 : 85/768
2024-03-30 23:28:33,136 [inflora.py] => Layer 12 : 185/768
2024-03-30 23:28:45,193 [trainer.py] => Time:848.7147040367126
2024-03-30 23:28:54,942 [trainer.py] => Time:9.749255418777466
2024-03-30 23:28:54,943 [inflora.py] => Exemplar size: 0
2024-03-30 23:28:54,943 [trainer.py] => CNN: {'total': 81.15, '00-19': 81.38, '20-39': 81.4, '40-59': 79.45, '60-79': 81.88, 'old': 80.92, 'new': 81.88}
2024-03-30 23:28:54,943 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15]
2024-03-30 23:28:54,943 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16]
2024-03-30 23:28:54,943 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471]
2024-03-30 23:28:54,946 [trainer.py] => All params: 111348451
2024-03-30 23:28:54,948 [trainer.py] => Trainable params: 199700
2024-03-30 23:28:54,948 [inflora.py] => Learning on 80-100
2024-03-30 23:44:37,243 [inflora.py] => Task 4, Epoch 50/50 => Loss 0.170, Train_accy 94.81
2024-03-30 23:44:55,725 [inflora.py] => Layer 1 : 9/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 2 : 18/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 3 : 35/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 4 : 47/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 5 : 71/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 6 : 68/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 7 : 82/768
2024-03-30 23:44:55,727 [inflora.py] => Layer 8 : 92/768
2024-03-30 23:44:55,728 [inflora.py] => Layer 9 : 156/768
2024-03-30 23:44:55,728 [inflora.py] => Layer 10 : 191/768
2024-03-30 23:44:55,728 [inflora.py] => Layer 11 : 127/768
2024-03-30 23:44:55,728 [inflora.py] => Layer 12 : 295/768
2024-03-30 23:45:09,194 [trainer.py] => Time:974.246169090271
2024-03-30 23:45:21,219 [trainer.py] => Time:12.024638891220093
2024-03-30 23:45:21,219 [inflora.py] => Exemplar size: 0
2024-03-30 23:45:21,220 [trainer.py] => CNN: {'total': 81.1, '00-19': 81.81, '20-39': 80.52, '40-59': 77.14, '60-79': 79.57, '80-99': 84.53, 'old': 80.06, 'new': 84.53}
2024-03-30 23:45:21,220 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1]
2024-03-30 23:45:21,220 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6]
2024-03-30 23:45:21,220 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501]
2024-03-30 23:45:21,222 [trainer.py] => All params: 111348451
2024-03-30 23:45:21,224 [trainer.py] => Trainable params: 199700
2024-03-30 23:45:21,224 [inflora.py] => Learning on 100-120
2024-03-30 23:58:19,035 [inflora.py] => Task 5, Epoch 50/50 => Loss 0.192, Train_accy 94.89
2024-03-30 23:58:54,970 [inflora.py] => Layer 1 : 10/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 2 : 21/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 3 : 43/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 4 : 58/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 5 : 84/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 6 : 84/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 7 : 100/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 8 : 113/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 9 : 195/768
2024-03-30 23:58:54,972 [inflora.py] => Layer 10 : 246/768
2024-03-30 23:58:54,973 [inflora.py] => Layer 11 : 173/768
2024-03-30 23:58:54,973 [inflora.py] => Layer 12 : 368/768
2024-03-30 23:59:07,049 [trainer.py] => Time:825.824146270752
2024-03-30 23:59:21,161 [trainer.py] => Time:14.112430572509766
2024-03-30 23:59:21,162 [inflora.py] => Exemplar size: 0
2024-03-30 23:59:21,162 [trainer.py] => CNN: {'total': 79.87, '00-19': 80.8, '20-39': 81.83, '40-59': 74.36, '60-79': 78.86, '80-99': 81.77, '100-119': 79.11, 'old': 80.01, 'new': 79.11}
2024-03-30 23:59:21,162 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87]
2024-03-30 23:59:21,162 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6]
2024-03-30 23:59:21,162 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461]
2024-03-30 23:59:21,164 [trainer.py] => All params: 111348451
2024-03-30 23:59:21,167 [trainer.py] => Trainable params: 199700
2024-03-30 23:59:21,167 [inflora.py] => Learning on 120-140
2024-03-31 00:13:03,488 [inflora.py] => Task 6, Epoch 50/50 => Loss 0.240, Train_accy 93.20
2024-03-31 00:13:20,082 [inflora.py] => Layer 1 : 10/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 2 : 26/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 3 : 55/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 4 : 74/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 5 : 106/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 6 : 106/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 7 : 128/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 8 : 146/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 9 : 254/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 10 : 325/768
2024-03-31 00:13:20,082 [inflora.py] => Layer 11 : 244/768
2024-03-31 00:13:20,083 [inflora.py] => Layer 12 : 475/768
2024-03-31 00:13:30,316 [trainer.py] => Time:849.1494932174683
2024-03-31 00:13:46,188 [trainer.py] => Time:15.87171983718872
2024-03-31 00:13:46,189 [inflora.py] => Exemplar size: 0
2024-03-31 00:13:46,189 [trainer.py] => CNN: {'total': 76.39, '00-19': 78.51, '20-39': 79.65, '40-59': 73.67, '60-79': 73.0, '80-99': 78.31, '100-119': 74.46, '120-139': 74.79, 'old': 76.65, 'new': 74.79}
2024-03-31 00:13:46,189 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39]
2024-03-31 00:13:46,189 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1]
2024-03-31 00:13:46,189 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763]
2024-03-31 00:13:46,191 [trainer.py] => All params: 111348451
2024-03-31 00:13:46,193 [trainer.py] => Trainable params: 199700
2024-03-31 00:13:46,193 [inflora.py] => Learning on 140-160
2024-03-31 00:24:37,444 [inflora.py] => Task 7, Epoch 50/50 => Loss 0.239, Train_accy 92.39
2024-03-31 00:24:53,618 [inflora.py] => Layer 1 : 11/768
2024-03-31 00:24:53,618 [inflora.py] => Layer 2 : 28/768
2024-03-31 00:24:53,618 [inflora.py] => Layer 3 : 60/768
2024-03-31 00:24:53,618 [inflora.py] => Layer 4 : 85/768
2024-03-31 00:24:53,618 [inflora.py] => Layer 5 : 119/768
2024-03-31 00:24:53,618 [inflora.py] => Layer 6 : 125/768
2024-03-31 00:24:53,619 [inflora.py] => Layer 7 : 153/768
2024-03-31 00:24:53,619 [inflora.py] => Layer 8 : 179/768
2024-03-31 00:24:53,619 [inflora.py] => Layer 9 : 299/768
2024-03-31 00:24:53,619 [inflora.py] => Layer 10 : 372/768
2024-03-31 00:24:53,619 [inflora.py] => Layer 11 : 298/768
2024-03-31 00:24:53,619 [inflora.py] => Layer 12 : 509/768
2024-03-31 00:25:03,367 [trainer.py] => Time:677.1743595600128
2024-03-31 00:25:21,003 [trainer.py] => Time:17.63573145866394
2024-03-31 00:25:21,004 [inflora.py] => Exemplar size: 0
2024-03-31 00:25:21,004 [trainer.py] => CNN: {'total': 75.43, '00-19': 79.08, '20-39': 78.92, '40-59': 71.13, '60-79': 71.76, '80-99': 78.59, '100-119': 75.54, '120-139': 72.08, '140-159': 72.1, 'old': 75.76, 'new': 72.1}
2024-03-31 00:25:21,004 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39, 75.43]
2024-03-31 00:25:21,004 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1, 86.45]
2024-03-31 00:25:21,004 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763, 0.7995726495726496]
2024-03-31 00:25:21,006 [trainer.py] => All params: 111348451
2024-03-31 00:25:21,008 [trainer.py] => Trainable params: 199700
2024-03-31 00:25:21,008 [inflora.py] => Learning on 160-180
2024-03-31 00:40:14,332 [inflora.py] => Task 8, Epoch 50/50 => Loss 0.138, Train_accy 96.34
2024-03-31 00:41:01,265 [inflora.py] => Layer 1 : 13/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 2 : 38/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 3 : 85/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 4 : 122/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 5 : 171/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 6 : 181/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 7 : 216/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 8 : 250/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 9 : 384/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 10 : 469/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 11 : 408/768
2024-03-31 00:41:01,266 [inflora.py] => Layer 12 : 572/768
2024-03-31 00:41:14,956 [trainer.py] => Time:953.947772026062
2024-03-31 00:41:35,325 [trainer.py] => Time:20.368398189544678
2024-03-31 00:41:35,325 [inflora.py] => Exemplar size: 0
2024-03-31 00:41:35,325 [trainer.py] => CNN: {'total': 75.99, '00-19': 79.94, '20-39': 79.8, '40-59': 69.75, '60-79': 71.94, '80-99': 78.31, '100-119': 75.36, '120-139': 69.71, '140-159': 70.69, '160-179': 82.77, 'old': 75.09, 'new': 82.77}
2024-03-31 00:41:35,325 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39, 75.43, 75.99]
2024-03-31 00:41:35,325 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1, 86.45, 87.15]
2024-03-31 00:41:35,325 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763, 0.7995726495726496, 0.8006036596868515]
2024-03-31 00:41:35,328 [trainer.py] => All params: 111348451
2024-03-31 00:41:35,331 [trainer.py] => Trainable params: 199700
2024-03-31 00:41:35,331 [inflora.py] => Learning on 180-200
2024-03-31 00:58:15,440 [inflora.py] => Task 9, Epoch 50/50 => Loss 0.195, Train_accy 94.93
2024-03-31 00:58:51,241 [inflora.py] => Layer 1 : 17/768
2024-03-31 00:58:51,244 [inflora.py] => Layer 2 : 52/768
2024-03-31 00:58:51,244 [inflora.py] => Layer 3 : 124/768
2024-03-31 00:58:51,244 [inflora.py] => Layer 4 : 178/768
2024-03-31 00:58:51,244 [inflora.py] => Layer 5 : 237/768
2024-03-31 00:58:51,244 [inflora.py] => Layer 6 : 254/768
2024-03-31 00:58:51,244 [inflora.py] => Layer 7 : 304/768
2024-03-31 00:58:51,245 [inflora.py] => Layer 8 : 353/768
2024-03-31 00:58:51,245 [inflora.py] => Layer 9 : 483/768
2024-03-31 00:58:51,245 [inflora.py] => Layer 10 : 558/768
2024-03-31 00:58:51,245 [inflora.py] => Layer 11 : 524/768
2024-03-31 00:58:51,245 [inflora.py] => Layer 12 : 651/768
2024-03-31 00:59:05,378 [trainer.py] => Time:1050.046481847763
2024-03-31 00:59:27,318 [trainer.py] => Time:21.939532995224
2024-03-31 00:59:27,318 [inflora.py] => Exemplar size: 0
2024-03-31 00:59:27,318 [trainer.py] => CNN: {'total': 75.67, '00-19': 79.23, '20-39': 79.51, '40-59': 70.9, '60-79': 71.94, '80-99': 76.1, '100-119': 74.29, '120-139': 68.87, '140-159': 69.27, '160-179': 82.45, '180-199': 78.54, 'old': 75.29, 'new': 78.54}
2024-03-31 00:59:27,318 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39, 75.43, 75.99, 75.67]
2024-03-31 00:59:27,318 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1, 86.45, 87.15, 87.12]
2024-03-31 00:59:27,318 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763, 0.7995726495726496, 0.8006036596868515, 0.7935]
2024-03-31 20:18:32,137 [trainer.py] => config: configs/mimg10_inflora.json
2024-03-31 20:18:32,137 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 20:18:32,137 [trainer.py] => prefix: reproduce
2024-03-31 20:18:32,137 [trainer.py] => dataset: ImageNet_R
2024-03-31 20:18:32,137 [trainer.py] => data_path: data/imagenet-r
2024-03-31 20:18:32,137 [trainer.py] => memory_size: 0
2024-03-31 20:18:32,137 [trainer.py] => memory_per_class: 0
2024-03-31 20:18:32,137 [trainer.py] => fixed_memory: True
2024-03-31 20:18:32,137 [trainer.py] => shuffle: False
2024-03-31 20:18:32,137 [trainer.py] => init_cls: 20
2024-03-31 20:18:32,137 [trainer.py] => increment: 20
2024-03-31 20:18:32,137 [trainer.py] => model_name: InfLoRA
2024-03-31 20:18:32,137 [trainer.py] => net_type: sip
2024-03-31 20:18:32,137 [trainer.py] => embd_dim: 768
2024-03-31 20:18:32,137 [trainer.py] => num_heads: 12
2024-03-31 20:18:32,137 [trainer.py] => total_sessions: 10
2024-03-31 20:18:32,137 [trainer.py] => seed: 0
2024-03-31 20:18:32,137 [trainer.py] => EPSILON: 1e-08
2024-03-31 20:18:32,137 [trainer.py] => init_epoch: 50
2024-03-31 20:18:32,137 [trainer.py] => optim: adam
2024-03-31 20:18:32,138 [trainer.py] => init_lr: 0.0005
2024-03-31 20:18:32,138 [trainer.py] => init_lr_decay: 0.1
2024-03-31 20:18:32,138 [trainer.py] => init_weight_decay: 0.0
2024-03-31 20:18:32,138 [trainer.py] => epochs: 50
2024-03-31 20:18:32,138 [trainer.py] => lrate: 0.0005
2024-03-31 20:18:32,138 [trainer.py] => lrate_decay: 0.1
2024-03-31 20:18:32,138 [trainer.py] => batch_size: 128
2024-03-31 20:18:32,138 [trainer.py] => weight_decay: 0.0
2024-03-31 20:18:32,138 [trainer.py] => rank: 10
2024-03-31 20:18:32,138 [trainer.py] => lamb: 0.98
2024-03-31 20:18:32,138 [trainer.py] => lame: 1.0
2024-03-31 20:18:32,138 [trainer.py] => num_workers: 16
2024-03-31 20:18:32,290 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-31 20:18:36,311 [trainer.py] => All params: 111348451
2024-03-31 20:18:36,315 [trainer.py] => Trainable params: 111348451
2024-03-31 20:18:36,315 [inflora.py] => Learning on 0-20
2024-03-31 20:34:16,222 [trainer.py] => config: configs/mimg10_inflora.json
2024-03-31 20:34:16,222 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 20:34:16,222 [trainer.py] => prefix: reproduce
2024-03-31 20:34:16,222 [trainer.py] => dataset: ImageNet_R
2024-03-31 20:34:16,222 [trainer.py] => data_path: data/imagenet-r
2024-03-31 20:34:16,222 [trainer.py] => memory_size: 0
2024-03-31 20:34:16,222 [trainer.py] => memory_per_class: 0
2024-03-31 20:34:16,222 [trainer.py] => fixed_memory: True
2024-03-31 20:34:16,222 [trainer.py] => shuffle: False
2024-03-31 20:34:16,222 [trainer.py] => init_cls: 20
2024-03-31 20:34:16,222 [trainer.py] => increment: 20
2024-03-31 20:34:16,222 [trainer.py] => model_name: InfLoRA
2024-03-31 20:34:16,222 [trainer.py] => net_type: sip
2024-03-31 20:34:16,222 [trainer.py] => embd_dim: 768
2024-03-31 20:34:16,222 [trainer.py] => num_heads: 12
2024-03-31 20:34:16,222 [trainer.py] => total_sessions: 10
2024-03-31 20:34:16,222 [trainer.py] => seed: 0
2024-03-31 20:34:16,222 [trainer.py] => EPSILON: 1e-08
2024-03-31 20:34:16,222 [trainer.py] => init_epoch: 50
2024-03-31 20:34:16,222 [trainer.py] => optim: adam
2024-03-31 20:34:16,222 [trainer.py] => init_lr: 0.0005
2024-03-31 20:34:16,222 [trainer.py] => init_lr_decay: 0.1
2024-03-31 20:34:16,222 [trainer.py] => init_weight_decay: 0.0
2024-03-31 20:34:16,222 [trainer.py] => epochs: 50
2024-03-31 20:34:16,222 [trainer.py] => lrate: 0.0005
2024-03-31 20:34:16,222 [trainer.py] => lrate_decay: 0.1
2024-03-31 20:34:16,222 [trainer.py] => batch_size: 128
2024-03-31 20:34:16,222 [trainer.py] => weight_decay: 0.0
2024-03-31 20:34:16,223 [trainer.py] => rank: 10
2024-03-31 20:34:16,223 [trainer.py] => lamb: 0.98
2024-03-31 20:34:16,223 [trainer.py] => lame: 1.0
2024-03-31 20:34:16,223 [trainer.py] => num_workers: 16
2024-03-31 20:34:16,308 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-31 20:34:19,972 [trainer.py] => All params: 111348451
2024-03-31 20:34:19,974 [trainer.py] => Trainable params: 111348451
2024-03-31 20:34:19,975 [inflora.py] => Learning on 0-20
2024-03-31 20:52:33,547 [inflora.py] => Task 0, Epoch 50/50 => Loss 0.154, Train_accy 96.01
2024-03-31 20:52:58,912 [trainer.py] => Time:1118.937583208084
2024-03-31 20:53:05,125 [trainer.py] => Time:6.212148427963257
2024-03-31 20:53:05,125 [inflora.py] => Exemplar size: 0
2024-03-31 20:53:05,125 [trainer.py] => CNN: {'total': 91.4, '00-19': 91.4, 'old': 0, 'new': 91.4}
2024-03-31 20:53:05,125 [trainer.py] => CNN top1 curve: [91.4]
2024-03-31 20:53:05,126 [trainer.py] => CNN top1 with task curve: [91.4]
2024-03-31 20:53:05,126 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 20:53:05,131 [trainer.py] => All params: 111348451
2024-03-31 20:53:05,135 [trainer.py] => Trainable params: 199700
2024-03-31 20:53:05,136 [inflora.py] => Learning on 20-40
2024-03-31 21:13:41,254 [inflora.py] => Task 1, Epoch 50/50 => Loss 0.160, Train_accy 94.93
2024-03-31 21:14:14,934 [trainer.py] => Time:1269.7985343933105
2024-03-31 21:14:25,091 [trainer.py] => Time:10.155559778213501
2024-03-31 21:14:25,091 [inflora.py] => Exemplar size: 0
2024-03-31 21:14:25,091 [trainer.py] => CNN: {'total': 87.88, '00-19': 87.97, '20-39': 87.79, 'old': 87.97, 'new': 87.79}
2024-03-31 21:14:25,091 [trainer.py] => CNN top1 curve: [91.4, 87.88]
2024-03-31 21:14:25,091 [trainer.py] => CNN top1 with task curve: [91.4, 91.13]
2024-03-31 21:14:25,091 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394]
2024-03-31 21:14:25,093 [trainer.py] => All params: 111348451
2024-03-31 21:14:25,095 [trainer.py] => Trainable params: 199700
2024-03-31 21:14:25,095 [inflora.py] => Learning on 40-60
2024-03-31 21:27:29,882 [inflora.py] => Task 2, Epoch 50/50 => Loss 0.196, Train_accy 94.66
2024-03-31 21:27:56,564 [trainer.py] => Time:811.4694225788116
2024-03-31 21:28:09,419 [trainer.py] => Time:12.854488611221313
2024-03-31 21:28:09,419 [inflora.py] => Exemplar size: 0
2024-03-31 21:28:09,420 [trainer.py] => CNN: {'total': 84.28, '00-19': 85.53, '20-39': 86.63, '40-59': 78.52, 'old': 86.08, 'new': 78.52}
2024-03-31 21:28:09,420 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28]
2024-03-31 21:28:09,420 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57]
2024-03-31 21:28:09,420 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901]
2024-03-31 21:28:09,422 [trainer.py] => All params: 111348451
2024-03-31 21:28:09,423 [trainer.py] => Trainable params: 199700
2024-03-31 21:28:09,423 [inflora.py] => Learning on 60-80
2024-03-31 21:45:01,415 [inflora.py] => Task 3, Epoch 50/50 => Loss 0.164, Train_accy 95.19
2024-03-31 21:45:31,437 [trainer.py] => Time:1042.0134043693542
2024-03-31 21:45:47,449 [trainer.py] => Time:16.008379459381104
2024-03-31 21:45:47,449 [inflora.py] => Exemplar size: 0
2024-03-31 21:45:47,449 [trainer.py] => CNN: {'total': 81.15, '00-19': 81.38, '20-39': 81.4, '40-59': 79.45, '60-79': 81.88, 'old': 80.92, 'new': 81.88}
2024-03-31 21:45:47,449 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15]
2024-03-31 21:45:47,450 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16]
2024-03-31 21:45:47,450 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471]
2024-03-31 21:45:47,451 [trainer.py] => All params: 111348451
2024-03-31 21:45:47,453 [trainer.py] => Trainable params: 199700
2024-03-31 21:45:47,453 [inflora.py] => Learning on 80-100
2024-03-31 22:05:42,996 [inflora.py] => Task 4, Epoch 50/50 => Loss 0.170, Train_accy 94.81
2024-03-31 22:06:15,608 [trainer.py] => Time:1228.1548600196838
2024-03-31 22:06:32,827 [trainer.py] => Time:17.21792483329773
2024-03-31 22:06:32,827 [inflora.py] => Exemplar size: 0
2024-03-31 22:06:32,827 [trainer.py] => CNN: {'total': 81.1, '00-19': 81.81, '20-39': 80.52, '40-59': 77.14, '60-79': 79.57, '80-99': 84.53, 'old': 80.06, 'new': 84.53}
2024-03-31 22:06:32,827 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1]
2024-03-31 22:06:32,827 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6]
2024-03-31 22:06:32,827 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501]
2024-03-31 22:06:32,830 [trainer.py] => All params: 111348451
2024-03-31 22:06:32,831 [trainer.py] => Trainable params: 199700
2024-03-31 22:06:32,831 [inflora.py] => Learning on 100-120
2024-03-31 22:23:03,397 [inflora.py] => Task 5, Epoch 50/50 => Loss 0.192, Train_accy 94.89
2024-03-31 22:23:32,076 [trainer.py] => Time:1019.2449750900269
2024-03-31 22:23:52,138 [trainer.py] => Time:20.06086564064026
2024-03-31 22:23:52,138 [inflora.py] => Exemplar size: 0
2024-03-31 22:23:52,138 [trainer.py] => CNN: {'total': 79.87, '00-19': 80.8, '20-39': 81.83, '40-59': 74.36, '60-79': 78.86, '80-99': 81.77, '100-119': 79.11, 'old': 80.01, 'new': 79.11}
2024-03-31 22:23:52,138 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87]
2024-03-31 22:23:52,138 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6]
2024-03-31 22:23:52,138 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461]
2024-03-31 22:23:52,140 [trainer.py] => All params: 111348451
2024-03-31 22:23:52,142 [trainer.py] => Trainable params: 199700
2024-03-31 22:23:52,142 [inflora.py] => Learning on 120-140
2024-03-31 22:40:28,131 [inflora.py] => Task 6, Epoch 50/50 => Loss 0.240, Train_accy 93.20
2024-03-31 22:40:55,690 [trainer.py] => Time:1023.5481851100922
2024-03-31 22:41:19,242 [trainer.py] => Time:23.55111837387085
2024-03-31 22:41:19,242 [inflora.py] => Exemplar size: 0
2024-03-31 22:41:19,242 [trainer.py] => CNN: {'total': 76.39, '00-19': 78.51, '20-39': 79.65, '40-59': 73.67, '60-79': 73.0, '80-99': 78.31, '100-119': 74.46, '120-139': 74.79, 'old': 76.65, 'new': 74.79}
2024-03-31 22:41:19,242 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39]
2024-03-31 22:41:19,242 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1]
2024-03-31 22:41:19,243 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763]
2024-03-31 22:41:19,248 [trainer.py] => All params: 111348451
2024-03-31 22:41:19,253 [trainer.py] => Trainable params: 199700
2024-03-31 22:41:19,253 [inflora.py] => Learning on 140-160
2024-03-31 22:55:04,822 [inflora.py] => Task 7, Epoch 50/50 => Loss 0.239, Train_accy 92.56
2024-03-31 22:55:29,538 [trainer.py] => Time:850.2843623161316
2024-03-31 22:55:58,406 [trainer.py] => Time:28.86760950088501
2024-03-31 22:55:58,406 [inflora.py] => Exemplar size: 0
2024-03-31 22:55:58,406 [trainer.py] => CNN: {'total': 75.41, '00-19': 78.94, '20-39': 79.22, '40-59': 71.59, '60-79': 71.58, '80-99': 77.9, '100-119': 75.18, '120-139': 72.76, '140-159': 72.1, 'old': 75.73, 'new': 72.1}
2024-03-31 22:55:58,407 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39, 75.41]
2024-03-31 22:55:58,407 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1, 86.54]
2024-03-31 22:55:58,407 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763, 0.8]
2024-03-31 22:55:58,412 [trainer.py] => All params: 111348451
2024-03-31 22:55:58,417 [trainer.py] => Trainable params: 199700
2024-03-31 22:55:58,418 [inflora.py] => Learning on 160-180
2024-03-31 23:06:50,172 [inflora.py] => Task 8, Epoch 50/50 => Loss 0.138, Train_accy 96.10
2024-03-31 23:07:11,151 [trainer.py] => Time:672.7337744235992
2024-03-31 23:07:23,508 [trainer.py] => Time:12.356288433074951
2024-03-31 23:07:23,508 [inflora.py] => Exemplar size: 0
2024-03-31 23:07:23,508 [trainer.py] => CNN: {'total': 76.08, '00-19': 78.8, '20-39': 80.09, '40-59': 70.67, '60-79': 71.94, '80-99': 78.45, '100-119': 76.25, '120-139': 70.22, '140-159': 70.69, '160-179': 82.45, 'old': 75.24, 'new': 82.45}
2024-03-31 23:07:23,508 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39, 75.41, 76.08]
2024-03-31 23:07:23,509 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1, 86.54, 87.34]
2024-03-31 23:07:23,509 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763, 0.8, 0.8004150160347104]
2024-03-31 23:07:23,510 [trainer.py] => All params: 111348451
2024-03-31 23:07:23,512 [trainer.py] => Trainable params: 199700
2024-03-31 23:07:23,512 [inflora.py] => Learning on 180-200
2024-03-31 23:18:42,848 [inflora.py] => Task 9, Epoch 50/50 => Loss 0.196, Train_accy 94.89
2024-03-31 23:19:04,042 [trainer.py] => Time:700.5301570892334
2024-03-31 23:19:17,643 [trainer.py] => Time:13.600558519363403
2024-03-31 23:19:17,644 [inflora.py] => Exemplar size: 0
2024-03-31 23:19:17,644 [trainer.py] => CNN: {'total': 75.35, '00-19': 78.51, '20-39': 78.63, '40-59': 71.36, '60-79': 71.94, '80-99': 75.83, '100-119': 74.29, '120-139': 68.7, '140-159': 69.74, '160-179': 81.64, '180-199': 77.97, 'old': 75.0, 'new': 77.97}
2024-03-31 23:19:17,644 [trainer.py] => CNN top1 curve: [91.4, 87.88, 84.28, 81.15, 81.1, 79.87, 76.39, 75.41, 76.08, 75.35]
2024-03-31 23:19:17,644 [trainer.py] => CNN top1 with task curve: [91.4, 91.13, 88.57, 88.16, 88.6, 88.6, 87.1, 86.54, 87.34, 87.12]
2024-03-31 23:19:17,644 [trainer.py] => CNN top1 task curve: [1.0, 0.9393939393939394, 0.9136888400219901, 0.871536523929471, 0.8634900193174501, 0.8461538461538461, 0.8111346018322763, 0.8, 0.8004150160347104, 0.7906666666666666]
