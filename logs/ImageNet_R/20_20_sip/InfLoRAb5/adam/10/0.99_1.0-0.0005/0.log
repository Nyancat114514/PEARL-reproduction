2024-03-30 22:05:50,789 [trainer.py] => config: configs/mimg10_inflorab5.json
2024-03-30 22:05:50,789 [trainer.py] => device: [device(type='cuda', index=0)]
2024-03-30 22:05:50,789 [trainer.py] => prefix: reproduce
2024-03-30 22:05:50,789 [trainer.py] => dataset: ImageNet_R
2024-03-30 22:05:50,789 [trainer.py] => data_path: data/imagenet-r
2024-03-30 22:05:50,789 [trainer.py] => memory_size: 0
2024-03-30 22:05:50,789 [trainer.py] => memory_per_class: 0
2024-03-30 22:05:50,789 [trainer.py] => fixed_memory: True
2024-03-30 22:05:50,789 [trainer.py] => shuffle: False
2024-03-30 22:05:50,789 [trainer.py] => init_cls: 20
2024-03-30 22:05:50,789 [trainer.py] => increment: 20
2024-03-30 22:05:50,789 [trainer.py] => model_name: InfLoRAb5
2024-03-30 22:05:50,789 [trainer.py] => net_type: sip
2024-03-30 22:05:50,789 [trainer.py] => embd_dim: 768
2024-03-30 22:05:50,789 [trainer.py] => num_heads: 12
2024-03-30 22:05:50,789 [trainer.py] => total_sessions: 10
2024-03-30 22:05:50,790 [trainer.py] => seed: 0
2024-03-30 22:05:50,790 [trainer.py] => EPSILON: 1e-08
2024-03-30 22:05:50,790 [trainer.py] => init_epoch: 50
2024-03-30 22:05:50,790 [trainer.py] => optim: adam
2024-03-30 22:05:50,790 [trainer.py] => init_lr: 0.0005
2024-03-30 22:05:50,790 [trainer.py] => init_lr_decay: 0.1
2024-03-30 22:05:50,790 [trainer.py] => init_weight_decay: 0.0
2024-03-30 22:05:50,790 [trainer.py] => epochs: 50
2024-03-30 22:05:50,790 [trainer.py] => lrate: 0.0005
2024-03-30 22:05:50,790 [trainer.py] => lrate_decay: 0.1
2024-03-30 22:05:50,790 [trainer.py] => batch_size: 128
2024-03-30 22:05:50,790 [trainer.py] => weight_decay: 0.0
2024-03-30 22:05:50,790 [trainer.py] => rank: 10
2024-03-30 22:05:50,790 [trainer.py] => lamb: 0.99
2024-03-30 22:05:50,790 [trainer.py] => lame: 1.0
2024-03-30 22:05:50,790 [trainer.py] => num_workers: 16
2024-03-30 22:05:50,967 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-30 22:05:59,882 [trainer.py] => All params: 109044251
2024-03-30 22:05:59,884 [trainer.py] => Trainable params: 109044251
2024-03-30 22:05:59,884 [inflorab5.py] => Learning on 0-20
2024-03-30 22:08:22,297 [trainer.py] => config: configs/mimg10_inflorab5.json
2024-03-30 22:08:22,297 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-30 22:08:22,297 [trainer.py] => prefix: reproduce
2024-03-30 22:08:22,297 [trainer.py] => dataset: ImageNet_R
2024-03-30 22:08:22,297 [trainer.py] => data_path: data/imagenet-r
2024-03-30 22:08:22,297 [trainer.py] => memory_size: 0
2024-03-30 22:08:22,297 [trainer.py] => memory_per_class: 0
2024-03-30 22:08:22,297 [trainer.py] => fixed_memory: True
2024-03-30 22:08:22,297 [trainer.py] => shuffle: False
2024-03-30 22:08:22,297 [trainer.py] => init_cls: 20
2024-03-30 22:08:22,297 [trainer.py] => increment: 20
2024-03-30 22:08:22,297 [trainer.py] => model_name: InfLoRAb5
2024-03-30 22:08:22,309 [trainer.py] => net_type: sip
2024-03-30 22:08:22,309 [trainer.py] => embd_dim: 768
2024-03-30 22:08:22,310 [trainer.py] => num_heads: 12
2024-03-30 22:08:22,310 [trainer.py] => total_sessions: 10
2024-03-30 22:08:22,310 [trainer.py] => seed: 0
2024-03-30 22:08:22,310 [trainer.py] => EPSILON: 1e-08
2024-03-30 22:08:22,310 [trainer.py] => init_epoch: 50
2024-03-30 22:08:22,310 [trainer.py] => optim: adam
2024-03-30 22:08:22,310 [trainer.py] => init_lr: 0.0005
2024-03-30 22:08:22,310 [trainer.py] => init_lr_decay: 0.1
2024-03-30 22:08:22,310 [trainer.py] => init_weight_decay: 0.0
2024-03-30 22:08:22,310 [trainer.py] => epochs: 50
2024-03-30 22:08:22,310 [trainer.py] => lrate: 0.0005
2024-03-30 22:08:22,310 [trainer.py] => lrate_decay: 0.1
2024-03-30 22:08:22,310 [trainer.py] => batch_size: 128
2024-03-30 22:08:22,310 [trainer.py] => weight_decay: 0.0
2024-03-30 22:08:22,310 [trainer.py] => rank: 10
2024-03-30 22:08:22,310 [trainer.py] => lamb: 0.99
2024-03-30 22:08:22,310 [trainer.py] => lame: 1.0
2024-03-30 22:08:22,310 [trainer.py] => num_workers: 16
2024-03-30 22:08:22,621 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-30 22:08:32,953 [trainer.py] => All params: 109044251
2024-03-30 22:08:32,955 [trainer.py] => Trainable params: 109044251
2024-03-30 22:08:32,955 [inflorab5.py] => Learning on 0-20
2024-03-30 22:31:02,234 [inflorab5.py] => Task 0, Epoch 50/50 => Loss 0.168, Train_accy 95.30
2024-03-30 22:31:53,729 [trainer.py] => Time:1400.7738964557648
2024-03-30 22:32:01,577 [trainer.py] => Time:7.848020076751709
2024-03-30 22:32:01,641 [inflorab5.py] => Exemplar size: 0
2024-03-30 22:32:01,641 [trainer.py] => CNN: {'total': 89.68, '00-19': 89.68, 'old': 0, 'new': 89.68}
2024-03-30 22:32:01,641 [trainer.py] => CNN top1 curve: [89.68]
2024-03-30 22:32:01,641 [trainer.py] => CNN top1 with task curve: [89.68]
2024-03-30 22:32:01,641 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-30 22:32:01,643 [trainer.py] => All params: 109044251
2024-03-30 22:32:01,645 [trainer.py] => Trainable params: 92180
2024-03-30 22:32:01,645 [inflorab5.py] => Learning on 20-40
2024-03-30 22:57:00,499 [inflorab5.py] => Task 1, Epoch 50/50 => Loss 0.213, Train_accy 93.59
2024-03-30 22:58:09,898 [trainer.py] => Time:1568.252780199051
2024-03-30 22:58:22,339 [trainer.py] => Time:12.440539598464966
2024-03-30 22:58:22,413 [inflorab5.py] => Exemplar size: 0
2024-03-30 22:58:22,415 [trainer.py] => CNN: {'total': 85.86, '00-19': 87.54, '20-39': 84.16, 'old': 87.54, 'new': 84.16}
2024-03-30 22:58:22,415 [trainer.py] => CNN top1 curve: [89.68, 85.86]
2024-03-30 22:58:22,415 [trainer.py] => CNN top1 with task curve: [89.68, 90.62]
2024-03-30 22:58:22,415 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214]
2024-03-30 22:58:22,417 [trainer.py] => All params: 109044251
2024-03-30 22:58:22,419 [trainer.py] => Trainable params: 92180
2024-03-30 22:58:22,419 [inflorab5.py] => Learning on 40-60
2024-03-30 23:14:39,620 [inflorab5.py] => Task 2, Epoch 50/50 => Loss 0.275, Train_accy 92.88
2024-03-30 23:15:01,564 [trainer.py] => Time:999.1445395946503
2024-03-30 23:15:11,476 [trainer.py] => Time:9.912226676940918
2024-03-30 23:15:11,533 [inflorab5.py] => Exemplar size: 0
2024-03-30 23:15:11,534 [trainer.py] => CNN: {'total': 80.81, '00-19': 85.67, '20-39': 81.98, '40-59': 71.13, 'old': 83.84, 'new': 71.13}
2024-03-30 23:15:11,534 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81]
2024-03-30 23:15:11,534 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46]
2024-03-30 23:15:11,534 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469]
2024-03-30 23:15:11,535 [trainer.py] => All params: 109044251
2024-03-30 23:15:11,536 [trainer.py] => Trainable params: 92180
2024-03-30 23:15:11,536 [inflorab5.py] => Learning on 60-80
2024-03-30 23:29:17,385 [inflorab5.py] => Task 3, Epoch 50/50 => Loss 0.209, Train_accy 93.76
2024-03-30 23:29:40,439 [trainer.py] => Time:868.9028542041779
2024-03-30 23:29:52,088 [trainer.py] => Time:11.648077964782715
2024-03-30 23:29:52,165 [inflorab5.py] => Exemplar size: 0
2024-03-30 23:29:52,165 [trainer.py] => CNN: {'total': 78.0, '00-19': 81.81, '20-39': 78.63, '40-59': 69.52, '60-79': 79.04, 'old': 77.68, 'new': 79.04}
2024-03-30 23:29:52,165 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0]
2024-03-30 23:29:52,165 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32]
2024-03-30 23:29:52,165 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105]
2024-03-30 23:29:52,167 [trainer.py] => All params: 109044251
2024-03-30 23:29:52,168 [trainer.py] => Trainable params: 92180
2024-03-30 23:29:52,168 [inflorab5.py] => Learning on 80-100
2024-03-30 23:46:04,774 [inflorab5.py] => Task 4, Epoch 50/50 => Loss 0.213, Train_accy 93.67
2024-03-30 23:46:30,246 [trainer.py] => Time:998.0774314403534
2024-03-30 23:46:45,169 [trainer.py] => Time:14.92308759689331
2024-03-30 23:46:45,244 [inflorab5.py] => Exemplar size: 0
2024-03-30 23:46:45,244 [trainer.py] => CNN: {'total': 77.91, '00-19': 83.24, '20-39': 78.78, '40-59': 69.75, '60-79': 76.73, '80-99': 77.76, 'old': 77.96, 'new': 77.76}
2024-03-30 23:46:45,244 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0, 77.91]
2024-03-30 23:46:45,244 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32, 87.8]
2024-03-30 23:46:45,244 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105, 0.8296844816484225]
2024-03-30 23:46:45,245 [trainer.py] => All params: 109044251
2024-03-30 23:46:45,246 [trainer.py] => Trainable params: 92180
2024-03-30 23:46:45,246 [inflorab5.py] => Learning on 100-120
2024-03-31 00:00:18,783 [inflorab5.py] => Task 5, Epoch 50/50 => Loss 0.240, Train_accy 93.44
2024-03-31 00:00:51,933 [trainer.py] => Time:846.6861894130707
2024-03-31 00:01:09,930 [trainer.py] => Time:17.996492624282837
2024-03-31 00:01:09,983 [inflorab5.py] => Exemplar size: 0
2024-03-31 00:01:09,983 [trainer.py] => CNN: {'total': 76.46, '00-19': 82.38, '20-39': 79.22, '40-59': 69.28, '60-79': 75.67, '80-99': 75.97, '100-119': 72.68, 'old': 77.14, 'new': 72.68}
2024-03-31 00:01:09,983 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0, 77.91, 76.46]
2024-03-31 00:01:09,983 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32, 87.8, 87.67]
2024-03-31 00:01:09,983 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105, 0.8296844816484225, 0.8101472995090017]
2024-03-31 00:01:09,985 [trainer.py] => All params: 109044251
2024-03-31 00:01:09,986 [trainer.py] => Trainable params: 92180
2024-03-31 00:01:09,987 [inflorab5.py] => Learning on 120-140
2024-03-31 00:15:18,838 [inflorab5.py] => Task 6, Epoch 50/50 => Loss 0.316, Train_accy 90.89
2024-03-31 00:15:40,735 [trainer.py] => Time:870.7483556270599
2024-03-31 00:16:00,151 [trainer.py] => Time:19.415303230285645
2024-03-31 00:16:00,188 [inflorab5.py] => Exemplar size: 0
2024-03-31 00:16:00,188 [trainer.py] => CNN: {'total': 74.63, '00-19': 82.52, '20-39': 77.91, '40-59': 67.44, '60-79': 72.11, '80-99': 75.55, '100-119': 69.46, '120-139': 72.93, 'old': 74.9, 'new': 72.93}
2024-03-31 00:16:00,188 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0, 77.91, 76.46, 74.63]
2024-03-31 00:16:00,188 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32, 87.8, 87.67, 86.89]
2024-03-31 00:16:00,188 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105, 0.8296844816484225, 0.8101472995090017, 0.7916373032652102]
2024-03-31 00:16:00,189 [trainer.py] => All params: 109044251
2024-03-31 00:16:00,190 [trainer.py] => Trainable params: 92180
2024-03-31 00:16:00,190 [inflorab5.py] => Learning on 140-160
2024-03-31 00:27:24,572 [inflorab5.py] => Task 7, Epoch 50/50 => Loss 0.234, Train_accy 92.99
2024-03-31 00:27:58,448 [trainer.py] => Time:718.2580370903015
2024-03-31 00:28:20,004 [trainer.py] => Time:21.554782152175903
2024-03-31 00:28:20,100 [inflorab5.py] => Exemplar size: 0
2024-03-31 00:28:20,100 [trainer.py] => CNN: {'total': 74.06, '00-19': 81.81, '20-39': 77.33, '40-59': 67.9, '60-79': 71.23, '80-99': 74.86, '100-119': 69.82, '120-139': 73.1, '140-159': 71.63, 'old': 74.3, 'new': 71.63}
2024-03-31 00:28:20,100 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0, 77.91, 76.46, 74.63, 74.06]
2024-03-31 00:28:20,100 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32, 87.8, 87.67, 86.89, 86.69]
2024-03-31 00:28:20,100 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105, 0.8296844816484225, 0.8101472995090017, 0.7916373032652102, 0.7837606837606838]
2024-03-31 00:28:20,103 [trainer.py] => All params: 109044251
2024-03-31 00:28:20,105 [trainer.py] => Trainable params: 92180
2024-03-31 00:28:20,105 [inflorab5.py] => Learning on 160-180
2024-03-31 00:44:09,293 [inflorab5.py] => Task 8, Epoch 50/50 => Loss 0.176, Train_accy 95.34
2024-03-31 00:44:56,271 [trainer.py] => Time:996.1661636829376
2024-03-31 00:45:21,768 [trainer.py] => Time:25.496668815612793
2024-03-31 00:45:21,819 [inflorab5.py] => Exemplar size: 0
2024-03-31 00:45:21,819 [trainer.py] => CNN: {'total': 74.16, '00-19': 81.95, '20-39': 76.74, '40-59': 67.67, '60-79': 70.16, '80-99': 74.86, '100-119': 69.11, '120-139': 71.57, '140-159': 68.56, '160-179': 80.68, 'old': 73.29, 'new': 80.68}
2024-03-31 00:45:21,819 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0, 77.91, 76.46, 74.63, 74.06, 74.16]
2024-03-31 00:45:21,819 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32, 87.8, 87.67, 86.89, 86.69, 87.12]
2024-03-31 00:45:21,819 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105, 0.8296844816484225, 0.8101472995090017, 0.7916373032652102, 0.7837606837606838, 0.77985285795133]
2024-03-31 00:45:21,821 [trainer.py] => All params: 109044251
2024-03-31 00:45:21,822 [trainer.py] => Trainable params: 92180
2024-03-31 00:45:21,822 [inflorab5.py] => Learning on 180-200
2024-03-31 01:02:12,102 [inflorab5.py] => Task 9, Epoch 50/50 => Loss 0.202, Train_accy 94.64
2024-03-31 01:03:17,691 [trainer.py] => Time:1075.8685820102692
2024-03-31 01:03:46,255 [trainer.py] => Time:28.563570976257324
2024-03-31 01:03:46,314 [inflorab5.py] => Exemplar size: 0
2024-03-31 01:03:46,314 [trainer.py] => CNN: {'total': 73.95, '00-19': 81.09, '20-39': 76.89, '40-59': 67.21, '60-79': 70.16, '80-99': 74.59, '100-119': 69.46, '120-139': 70.22, '140-159': 68.09, '160-179': 80.03, '180-199': 75.39, 'old': 73.76, 'new': 75.39}
2024-03-31 01:03:46,315 [trainer.py] => CNN top1 curve: [89.68, 85.86, 80.81, 78.0, 77.91, 76.46, 74.63, 74.06, 74.16, 73.95]
2024-03-31 01:03:46,315 [trainer.py] => CNN top1 with task curve: [89.68, 90.62, 88.46, 87.32, 87.8, 87.67, 86.89, 86.69, 87.12, 87.27]
2024-03-31 01:03:46,315 [trainer.py] => CNN top1 task curve: [1.0, 0.9213564213564214, 0.8752061572292469, 0.8425692695214105, 0.8296844816484225, 0.8101472995090017, 0.7916373032652102, 0.7837606837606838, 0.77985285795133, 0.7741666666666667]
