2024-03-31 11:06:52,119 [trainer.py] => config: configs/mimg10_inflora_ca.json
2024-03-31 11:06:52,119 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 11:06:52,119 [trainer.py] => prefix: reproduce
2024-03-31 11:06:52,119 [trainer.py] => dataset: ImageNet_R
2024-03-31 11:06:52,119 [trainer.py] => data_path: data/imagenet-r
2024-03-31 11:06:52,119 [trainer.py] => memory_size: 0
2024-03-31 11:06:52,119 [trainer.py] => memory_per_class: 0
2024-03-31 11:06:52,119 [trainer.py] => fixed_memory: True
2024-03-31 11:06:52,119 [trainer.py] => shuffle: False
2024-03-31 11:06:52,119 [trainer.py] => init_cls: 20
2024-03-31 11:06:52,119 [trainer.py] => increment: 20
2024-03-31 11:06:52,119 [trainer.py] => model_name: InfLoRA_CA
2024-03-31 11:06:52,119 [trainer.py] => net_type: sip
2024-03-31 11:06:52,119 [trainer.py] => embd_dim: 768
2024-03-31 11:06:52,119 [trainer.py] => num_heads: 12
2024-03-31 11:06:52,119 [trainer.py] => total_sessions: 10
2024-03-31 11:06:52,119 [trainer.py] => seed: 0
2024-03-31 11:06:52,120 [trainer.py] => EPSILON: 1e-08
2024-03-31 11:06:52,120 [trainer.py] => init_epoch: 50
2024-03-31 11:06:52,120 [trainer.py] => optim: sgd
2024-03-31 11:06:52,120 [trainer.py] => epochs: 50
2024-03-31 11:06:52,120 [trainer.py] => init_lr: 0.001
2024-03-31 11:06:52,120 [trainer.py] => init_lr_decay: 0.1
2024-03-31 11:06:52,120 [trainer.py] => init_weight_decay: 0.0
2024-03-31 11:06:52,120 [trainer.py] => lrate: 0.001
2024-03-31 11:06:52,120 [trainer.py] => lrate_decay: 0.1
2024-03-31 11:06:52,120 [trainer.py] => batch_size: 128
2024-03-31 11:06:52,120 [trainer.py] => weight_decay: 0.0
2024-03-31 11:06:52,120 [trainer.py] => rank: 10
2024-03-31 11:06:52,120 [trainer.py] => lamb: 0.95
2024-03-31 11:06:52,120 [trainer.py] => lame: 1.0
2024-03-31 11:06:52,120 [trainer.py] => num_workers: 16
2024-03-31 11:06:52,207 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-31 11:06:55,900 [trainer.py] => All params: 111348451
2024-03-31 11:06:55,903 [trainer.py] => Trainable params: 111348451
2024-03-31 11:06:55,903 [inflora_ca.py] => Learning on 0-20
2024-03-31 11:24:58,920 [inflora_ca.py] => Task 0, Epoch 50/50 => Loss 0.284, Train_accy 91.24
2024-03-31 11:25:47,626 [trainer.py] => Time:1131.722995519638
2024-03-31 11:34:21,968 [trainer.py] => config: configs/mimg10_inflora_ca.json
2024-03-31 11:34:21,968 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 11:34:21,968 [trainer.py] => prefix: reproduce
2024-03-31 11:34:21,968 [trainer.py] => dataset: ImageNet_R
2024-03-31 11:34:21,969 [trainer.py] => data_path: data/imagenet-r
2024-03-31 11:34:21,969 [trainer.py] => memory_size: 0
2024-03-31 11:34:21,969 [trainer.py] => memory_per_class: 0
2024-03-31 11:34:21,969 [trainer.py] => fixed_memory: True
2024-03-31 11:34:21,969 [trainer.py] => shuffle: False
2024-03-31 11:34:21,969 [trainer.py] => init_cls: 20
2024-03-31 11:34:21,969 [trainer.py] => increment: 20
2024-03-31 11:34:21,969 [trainer.py] => model_name: InfLoRA_CA
2024-03-31 11:34:21,969 [trainer.py] => net_type: sip
2024-03-31 11:34:21,969 [trainer.py] => embd_dim: 768
2024-03-31 11:34:21,969 [trainer.py] => num_heads: 12
2024-03-31 11:34:21,969 [trainer.py] => total_sessions: 10
2024-03-31 11:34:21,969 [trainer.py] => seed: 0
2024-03-31 11:34:21,969 [trainer.py] => EPSILON: 1e-08
2024-03-31 11:34:21,969 [trainer.py] => init_epoch: 50
2024-03-31 11:34:21,969 [trainer.py] => optim: sgd
2024-03-31 11:34:21,969 [trainer.py] => epochs: 50
2024-03-31 11:34:21,969 [trainer.py] => init_lr: 0.001
2024-03-31 11:34:21,969 [trainer.py] => init_lr_decay: 0.1
2024-03-31 11:34:21,969 [trainer.py] => init_weight_decay: 0.0
2024-03-31 11:34:21,969 [trainer.py] => lrate: 0.001
2024-03-31 11:34:21,969 [trainer.py] => lrate_decay: 0.1
2024-03-31 11:34:21,969 [trainer.py] => batch_size: 128
2024-03-31 11:34:21,969 [trainer.py] => weight_decay: 0.0
2024-03-31 11:34:21,969 [trainer.py] => rank: 10
2024-03-31 11:34:21,969 [trainer.py] => lamb: 0.95
2024-03-31 11:34:21,969 [trainer.py] => lame: 1.0
2024-03-31 11:34:21,969 [trainer.py] => num_workers: 16
2024-03-31 11:34:22,068 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-31 11:34:25,821 [trainer.py] => All params: 111348451
2024-03-31 11:34:25,824 [trainer.py] => Trainable params: 111348451
2024-03-31 11:34:25,824 [inflora_ca.py] => Learning on 0-20
2024-03-31 11:52:49,734 [inflora_ca.py] => Task 0, Epoch 50/50 => Loss 0.284, Train_accy 91.24
2024-03-31 11:53:43,384 [trainer.py] => Time:1157.559965133667
2024-03-31 11:59:52,546 [trainer.py] => config: configs/mimg10_inflora_ca.json
2024-03-31 11:59:52,546 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 11:59:52,546 [trainer.py] => prefix: reproduce
2024-03-31 11:59:52,546 [trainer.py] => dataset: ImageNet_R
2024-03-31 11:59:52,546 [trainer.py] => data_path: data/imagenet-r
2024-03-31 11:59:52,546 [trainer.py] => memory_size: 0
2024-03-31 11:59:52,546 [trainer.py] => memory_per_class: 0
2024-03-31 11:59:52,546 [trainer.py] => fixed_memory: True
2024-03-31 11:59:52,546 [trainer.py] => shuffle: False
2024-03-31 11:59:52,546 [trainer.py] => init_cls: 20
2024-03-31 11:59:52,546 [trainer.py] => increment: 20
2024-03-31 11:59:52,546 [trainer.py] => model_name: InfLoRA_CA
2024-03-31 11:59:52,546 [trainer.py] => net_type: sip
2024-03-31 11:59:52,546 [trainer.py] => embd_dim: 768
2024-03-31 11:59:52,546 [trainer.py] => num_heads: 12
2024-03-31 11:59:52,546 [trainer.py] => total_sessions: 10
2024-03-31 11:59:52,546 [trainer.py] => seed: 0
2024-03-31 11:59:52,546 [trainer.py] => EPSILON: 1e-08
2024-03-31 11:59:52,546 [trainer.py] => init_epoch: 50
2024-03-31 11:59:52,546 [trainer.py] => optim: sgd
2024-03-31 11:59:52,546 [trainer.py] => epochs: 50
2024-03-31 11:59:52,546 [trainer.py] => init_lr: 0.001
2024-03-31 11:59:52,546 [trainer.py] => init_lr_decay: 0.1
2024-03-31 11:59:52,546 [trainer.py] => init_weight_decay: 0.0
2024-03-31 11:59:52,546 [trainer.py] => lrate: 0.001
2024-03-31 11:59:52,546 [trainer.py] => lrate_decay: 0.1
2024-03-31 11:59:52,546 [trainer.py] => batch_size: 128
2024-03-31 11:59:52,546 [trainer.py] => weight_decay: 0.0
2024-03-31 11:59:52,546 [trainer.py] => rank: 10
2024-03-31 11:59:52,546 [trainer.py] => lamb: 0.95
2024-03-31 11:59:52,547 [trainer.py] => lame: 1.0
2024-03-31 11:59:52,547 [trainer.py] => num_workers: 16
2024-03-31 11:59:52,633 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-31 11:59:54,991 [trainer.py] => All params: 111348451
2024-03-31 11:59:54,993 [trainer.py] => Trainable params: 111348451
2024-03-31 11:59:54,993 [inflora_ca.py] => Learning on 0-20
2024-03-31 12:18:03,647 [inflora_ca.py] => Task 0, Epoch 50/50 => Loss 0.284, Train_accy 91.24
2024-03-31 12:18:56,434 [trainer.py] => Time:1141.4405517578125
2024-03-31 12:19:32,830 [trainer.py] => Time:36.395957469940186
2024-03-31 12:19:32,830 [inflora_ca.py] => Exemplar size: 0
2024-03-31 12:19:32,830 [trainer.py] => CNN: {'total': 90.11, '00-19': 90.11, 'old': 0, 'new': 90.11}
2024-03-31 12:19:32,831 [trainer.py] => CNN top1 curve: [90.11]
2024-03-31 12:19:32,831 [trainer.py] => CNN top1 with task curve: [90.11]
2024-03-31 12:19:32,831 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 12:19:32,833 [trainer.py] => All params: 111348451
2024-03-31 12:19:32,834 [trainer.py] => Trainable params: 199700
2024-03-31 12:19:32,834 [inflora_ca.py] => Learning on 20-40
2024-03-31 12:40:02,640 [inflora_ca.py] => Task 1, Epoch 50/50 => Loss 0.313, Train_accy 91.06
2024-03-31 12:41:11,189 [inflora_ca.py] => CA Task 1 => Loss 0.123, Test_accy 86.360
2024-03-31 12:41:19,363 [inflora_ca.py] => CA Task 1 => Loss 0.073, Test_accy 87.300
2024-03-31 12:41:27,546 [inflora_ca.py] => CA Task 1 => Loss 0.054, Test_accy 87.660
2024-03-31 12:41:35,835 [inflora_ca.py] => CA Task 1 => Loss 0.046, Test_accy 87.300
2024-03-31 12:41:43,990 [inflora_ca.py] => CA Task 1 => Loss 0.044, Test_accy 87.160
2024-03-31 12:41:43,991 [trainer.py] => Time:1331.1564075946808
2024-03-31 12:42:49,712 [trainer.py] => Time:65.72072696685791
2024-03-31 12:42:49,712 [inflora_ca.py] => Exemplar size: 0
2024-03-31 12:42:49,712 [trainer.py] => CNN: {'total': 87.16, '00-19': 86.53, '20-39': 87.79, 'old': 86.53, 'new': 87.79}
2024-03-31 12:42:49,712 [trainer.py] => CNN top1 curve: [90.11, 87.16]
2024-03-31 12:42:49,712 [trainer.py] => CNN top1 with task curve: [90.11, 90.62]
2024-03-31 12:42:49,712 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365]
2024-03-31 12:42:49,716 [trainer.py] => All params: 111348451
2024-03-31 12:42:49,720 [trainer.py] => Trainable params: 215080
2024-03-31 12:42:49,720 [inflora_ca.py] => Learning on 40-60
2024-03-31 12:56:18,372 [inflora_ca.py] => Task 2, Epoch 50/50 => Loss 0.368, Train_accy 89.04
2024-03-31 12:57:27,223 [inflora_ca.py] => CA Task 2 => Loss 0.082, Test_accy 84.610
2024-03-31 12:57:36,611 [inflora_ca.py] => CA Task 2 => Loss 0.055, Test_accy 85.540
2024-03-31 12:57:47,168 [inflora_ca.py] => CA Task 2 => Loss 0.044, Test_accy 85.870
2024-03-31 12:57:57,754 [inflora_ca.py] => CA Task 2 => Loss 0.035, Test_accy 85.820
2024-03-31 12:58:07,724 [inflora_ca.py] => CA Task 2 => Loss 0.033, Test_accy 85.980
2024-03-31 12:58:07,724 [trainer.py] => Time:918.0041396617889
2024-03-31 12:59:29,503 [trainer.py] => Time:81.77854418754578
2024-03-31 12:59:29,503 [inflora_ca.py] => Exemplar size: 0
2024-03-31 12:59:29,503 [trainer.py] => CNN: {'total': 85.98, '00-19': 85.1, '20-39': 86.77, '40-59': 86.14, 'old': 85.93, 'new': 86.14}
2024-03-31 12:59:29,503 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98]
2024-03-31 12:59:29,503 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39]
2024-03-31 12:59:29,503 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867]
2024-03-31 12:59:29,506 [trainer.py] => All params: 111348451
2024-03-31 12:59:29,507 [trainer.py] => Trainable params: 230460
2024-03-31 12:59:29,508 [inflora_ca.py] => Learning on 60-80
2024-03-31 13:16:46,946 [inflora_ca.py] => Task 3, Epoch 50/50 => Loss 0.335, Train_accy 89.70
2024-03-31 13:18:19,248 [inflora_ca.py] => CA Task 3 => Loss 0.068, Test_accy 84.630
2024-03-31 13:18:28,985 [inflora_ca.py] => CA Task 3 => Loss 0.048, Test_accy 84.340
2024-03-31 13:18:41,537 [inflora_ca.py] => CA Task 3 => Loss 0.040, Test_accy 83.800
2024-03-31 13:18:54,830 [inflora_ca.py] => CA Task 3 => Loss 0.035, Test_accy 83.800
2024-03-31 13:19:08,127 [inflora_ca.py] => CA Task 3 => Loss 0.031, Test_accy 84.090
2024-03-31 13:19:08,128 [trainer.py] => Time:1178.6201465129852
2024-03-31 13:20:58,165 [trainer.py] => Time:110.03759050369263
2024-03-31 13:20:58,166 [inflora_ca.py] => Exemplar size: 0
2024-03-31 13:20:58,166 [trainer.py] => CNN: {'total': 84.09, '00-19': 83.38, '20-39': 84.3, '40-59': 82.22, '60-79': 86.15, 'old': 83.45, 'new': 86.15}
2024-03-31 13:20:58,166 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09]
2024-03-31 13:20:58,166 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04]
2024-03-31 13:20:58,166 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178]
2024-03-31 13:20:58,168 [trainer.py] => All params: 111348451
2024-03-31 13:20:58,169 [trainer.py] => Trainable params: 245840
2024-03-31 13:20:58,170 [inflora_ca.py] => Learning on 80-100
2024-03-31 13:40:51,749 [inflora_ca.py] => Task 4, Epoch 50/50 => Loss 0.324, Train_accy 90.48
2024-03-31 13:42:01,220 [inflora_ca.py] => CA Task 4 => Loss 0.063, Test_accy 83.520
2024-03-31 13:42:10,416 [inflora_ca.py] => CA Task 4 => Loss 0.048, Test_accy 83.290
2024-03-31 13:42:20,717 [inflora_ca.py] => CA Task 4 => Loss 0.038, Test_accy 82.940
2024-03-31 13:42:30,021 [inflora_ca.py] => CA Task 4 => Loss 0.034, Test_accy 82.970
2024-03-31 13:42:39,958 [inflora_ca.py] => CA Task 4 => Loss 0.031, Test_accy 83.190
2024-03-31 13:42:39,958 [trainer.py] => Time:1301.7886204719543
2024-03-31 13:44:25,397 [trainer.py] => Time:105.4388256072998
2024-03-31 13:44:25,397 [inflora_ca.py] => Exemplar size: 0
2024-03-31 13:44:25,398 [trainer.py] => CNN: {'total': 83.19, '00-19': 82.38, '20-39': 82.27, '40-59': 83.37, '60-79': 82.77, '80-99': 85.08, 'old': 82.62, 'new': 85.08}
2024-03-31 13:44:25,398 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09, 83.19]
2024-03-31 13:44:25,398 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04, 88.86]
2024-03-31 13:44:25,398 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178, 0.8937540244687702]
2024-03-31 13:44:25,401 [trainer.py] => All params: 111348451
2024-03-31 13:44:25,405 [trainer.py] => Trainable params: 261220
2024-03-31 13:44:25,405 [inflora_ca.py] => Learning on 100-120
2024-03-31 13:54:06,962 [inflora_ca.py] => Task 5, Epoch 50/50 => Loss 0.292, Train_accy 91.95
2024-03-31 13:54:56,148 [inflora_ca.py] => CA Task 5 => Loss 0.062, Test_accy 81.860
2024-03-31 13:55:06,259 [inflora_ca.py] => CA Task 5 => Loss 0.045, Test_accy 81.150
2024-03-31 13:55:16,244 [inflora_ca.py] => CA Task 5 => Loss 0.036, Test_accy 82.000
2024-03-31 13:55:26,298 [inflora_ca.py] => CA Task 5 => Loss 0.032, Test_accy 82.160
2024-03-31 13:55:36,180 [inflora_ca.py] => CA Task 5 => Loss 0.030, Test_accy 82.000
2024-03-31 13:55:36,181 [trainer.py] => Time:670.7760715484619
2024-03-31 13:57:15,309 [trainer.py] => Time:99.12849807739258
2024-03-31 13:57:15,310 [inflora_ca.py] => Exemplar size: 0
2024-03-31 13:57:15,310 [trainer.py] => CNN: {'total': 82.0, '00-19': 80.66, '20-39': 80.81, '40-59': 82.91, '60-79': 82.06, '80-99': 83.29, '100-119': 82.68, 'old': 81.87, 'new': 82.68}
2024-03-31 13:57:15,310 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09, 83.19, 82.0]
2024-03-31 13:57:15,310 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04, 88.86, 88.43]
2024-03-31 13:57:15,310 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178, 0.8937540244687702, 0.88379705400982]
2024-03-31 13:57:15,312 [trainer.py] => All params: 111348451
2024-03-31 13:57:15,314 [trainer.py] => Trainable params: 276600
2024-03-31 13:57:15,314 [inflora_ca.py] => Learning on 120-140
2024-03-31 14:06:41,678 [inflora_ca.py] => Task 6, Epoch 50/50 => Loss 0.387, Train_accy 89.12
2024-03-31 14:07:36,867 [inflora_ca.py] => CA Task 6 => Loss 0.060, Test_accy 80.690
2024-03-31 14:07:48,112 [inflora_ca.py] => CA Task 6 => Loss 0.045, Test_accy 80.480
2024-03-31 14:07:59,357 [inflora_ca.py] => CA Task 6 => Loss 0.035, Test_accy 80.740
2024-03-31 14:08:10,863 [inflora_ca.py] => CA Task 6 => Loss 0.032, Test_accy 80.690
2024-03-31 14:08:23,050 [inflora_ca.py] => CA Task 6 => Loss 0.030, Test_accy 80.710
2024-03-31 14:08:23,051 [trainer.py] => Time:667.7369561195374
2024-03-31 14:10:43,525 [trainer.py] => Time:140.47385215759277
2024-03-31 14:10:43,525 [inflora_ca.py] => Exemplar size: 0
2024-03-31 14:10:43,525 [trainer.py] => CNN: {'total': 80.71, '00-19': 80.23, '20-39': 79.22, '40-59': 83.14, '60-79': 81.53, '80-99': 81.35, '100-119': 80.36, '120-139': 80.03, 'old': 80.82, 'new': 80.03}
2024-03-31 14:10:43,525 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09, 83.19, 82.0, 80.71]
2024-03-31 14:10:43,525 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04, 88.86, 88.43, 88.07]
2024-03-31 14:10:43,525 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178, 0.8937540244687702, 0.88379705400982, 0.873619920131548]
2024-03-31 14:10:43,529 [trainer.py] => All params: 111348451
2024-03-31 14:10:43,533 [trainer.py] => Trainable params: 291980
2024-03-31 14:10:43,533 [inflora_ca.py] => Learning on 140-160
2024-03-31 14:19:14,223 [inflora_ca.py] => Task 7, Epoch 50/50 => Loss 0.337, Train_accy 90.29
2024-03-31 14:20:05,818 [inflora_ca.py] => CA Task 7 => Loss 0.057, Test_accy 79.740
2024-03-31 14:20:18,259 [inflora_ca.py] => CA Task 7 => Loss 0.043, Test_accy 78.800
2024-03-31 14:20:30,580 [inflora_ca.py] => CA Task 7 => Loss 0.035, Test_accy 79.400
2024-03-31 14:20:42,799 [inflora_ca.py] => CA Task 7 => Loss 0.031, Test_accy 79.420
2024-03-31 14:20:55,064 [inflora_ca.py] => CA Task 7 => Loss 0.030, Test_accy 79.400
2024-03-31 14:20:55,065 [trainer.py] => Time:611.532201051712
2024-03-31 14:22:56,850 [trainer.py] => Time:121.78484797477722
2024-03-31 14:22:56,850 [inflora_ca.py] => Exemplar size: 0
2024-03-31 14:22:56,850 [trainer.py] => CNN: {'total': 79.4, '00-19': 79.66, '20-39': 78.63, '40-59': 81.52, '60-79': 80.28, '80-99': 82.18, '100-119': 77.68, '120-139': 77.33, '140-159': 77.3, 'old': 79.61, 'new': 77.3}
2024-03-31 14:22:56,850 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09, 83.19, 82.0, 80.71, 79.4]
2024-03-31 14:22:56,850 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04, 88.86, 88.43, 88.07, 87.01]
2024-03-31 14:22:56,850 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178, 0.8937540244687702, 0.88379705400982, 0.873619920131548, 0.8591880341880341]
2024-03-31 14:22:56,852 [trainer.py] => All params: 111348451
2024-03-31 14:22:56,854 [trainer.py] => Trainable params: 307360
2024-03-31 14:22:56,854 [inflora_ca.py] => Learning on 160-180
2024-03-31 14:33:08,021 [inflora_ca.py] => Task 8, Epoch 50/50 => Loss 0.261, Train_accy 92.97
2024-03-31 14:34:04,148 [inflora_ca.py] => CA Task 8 => Loss 0.049, Test_accy 79.490
2024-03-31 14:34:17,951 [inflora_ca.py] => CA Task 8 => Loss 0.037, Test_accy 79.650
2024-03-31 14:34:31,956 [inflora_ca.py] => CA Task 8 => Loss 0.032, Test_accy 79.830
2024-03-31 14:34:45,852 [inflora_ca.py] => CA Task 8 => Loss 0.030, Test_accy 79.660
2024-03-31 14:35:00,051 [inflora_ca.py] => CA Task 8 => Loss 0.027, Test_accy 80.120
2024-03-31 14:35:00,052 [trainer.py] => Time:723.1981871128082
2024-03-31 14:37:28,049 [trainer.py] => Time:147.9971947669983
2024-03-31 14:37:28,050 [inflora_ca.py] => Exemplar size: 0
2024-03-31 14:37:28,050 [trainer.py] => CNN: {'total': 80.12, '00-19': 80.09, '20-39': 79.07, '40-59': 82.45, '60-79': 80.28, '80-99': 81.49, '100-119': 77.86, '120-139': 76.99, '140-159': 74.23, '160-179': 86.96, 'old': 79.21, 'new': 86.96}
2024-03-31 14:37:28,050 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09, 83.19, 82.0, 80.71, 79.4, 80.12]
2024-03-31 14:37:28,050 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04, 88.86, 88.43, 88.07, 87.01, 88.32]
2024-03-31 14:37:28,050 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178, 0.8937540244687702, 0.88379705400982, 0.873619920131548, 0.8591880341880341, 0.8541784568949254]
2024-03-31 14:37:28,053 [trainer.py] => All params: 111348451
2024-03-31 14:37:28,055 [trainer.py] => Trainable params: 322740
2024-03-31 14:37:28,055 [inflora_ca.py] => Learning on 180-200
2024-03-31 14:49:43,922 [inflora_ca.py] => Task 9, Epoch 50/50 => Loss 0.286, Train_accy 91.97
2024-03-31 14:50:53,128 [inflora_ca.py] => CA Task 9 => Loss 0.050, Test_accy 79.200
2024-03-31 14:51:09,234 [inflora_ca.py] => CA Task 9 => Loss 0.040, Test_accy 79.350
2024-03-31 14:51:24,654 [inflora_ca.py] => CA Task 9 => Loss 0.035, Test_accy 79.230
2024-03-31 14:51:40,161 [inflora_ca.py] => CA Task 9 => Loss 0.030, Test_accy 79.400
2024-03-31 14:51:56,073 [inflora_ca.py] => CA Task 9 => Loss 0.027, Test_accy 79.480
2024-03-31 14:51:56,074 [trainer.py] => Time:868.0187976360321
2024-03-31 14:54:34,215 [trainer.py] => Time:158.14080142974854
2024-03-31 14:54:34,215 [inflora_ca.py] => Exemplar size: 0
2024-03-31 14:54:34,215 [trainer.py] => CNN: {'total': 79.48, '00-19': 79.08, '20-39': 78.2, '40-59': 82.91, '60-79': 80.28, '80-99': 81.08, '100-119': 76.96, '120-139': 74.28, '140-159': 73.29, '160-179': 85.99, '180-199': 81.12, 'old': 79.27, 'new': 81.12}
2024-03-31 14:54:34,215 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98, 84.09, 83.19, 82.0, 80.71, 79.4, 80.12, 79.48]
2024-03-31 14:54:34,215 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39, 89.04, 88.86, 88.43, 88.07, 87.01, 88.32, 88.3]
2024-03-31 14:54:34,215 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867, 0.90848026868178, 0.8937540244687702, 0.88379705400982, 0.873619920131548, 0.8591880341880341, 0.8541784568949254, 0.8441666666666666]
2024-03-31 19:08:59,476 [trainer.py] => config: configs/mimg10_inflora_ca.json
2024-03-31 19:08:59,476 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 19:08:59,476 [trainer.py] => prefix: reproduce
2024-03-31 19:08:59,476 [trainer.py] => dataset: ImageNet_R
2024-03-31 19:08:59,476 [trainer.py] => data_path: data/imagenet-r
2024-03-31 19:08:59,476 [trainer.py] => memory_size: 0
2024-03-31 19:08:59,476 [trainer.py] => memory_per_class: 0
2024-03-31 19:08:59,476 [trainer.py] => fixed_memory: True
2024-03-31 19:08:59,476 [trainer.py] => shuffle: False
2024-03-31 19:08:59,476 [trainer.py] => init_cls: 20
2024-03-31 19:08:59,477 [trainer.py] => increment: 20
2024-03-31 19:08:59,477 [trainer.py] => model_name: InfLoRA_CA
2024-03-31 19:08:59,477 [trainer.py] => net_type: sip
2024-03-31 19:08:59,477 [trainer.py] => embd_dim: 768
2024-03-31 19:08:59,477 [trainer.py] => num_heads: 12
2024-03-31 19:08:59,477 [trainer.py] => total_sessions: 10
2024-03-31 19:08:59,477 [trainer.py] => seed: 0
2024-03-31 19:08:59,477 [trainer.py] => EPSILON: 1e-08
2024-03-31 19:08:59,477 [trainer.py] => init_epoch: 50
2024-03-31 19:08:59,477 [trainer.py] => optim: sgd
2024-03-31 19:08:59,477 [trainer.py] => epochs: 50
2024-03-31 19:08:59,477 [trainer.py] => init_lr: 0.001
2024-03-31 19:08:59,477 [trainer.py] => init_lr_decay: 0.1
2024-03-31 19:08:59,477 [trainer.py] => init_weight_decay: 0.0
2024-03-31 19:08:59,477 [trainer.py] => lrate: 0.001
2024-03-31 19:08:59,477 [trainer.py] => lrate_decay: 0.1
2024-03-31 19:08:59,477 [trainer.py] => batch_size: 128
2024-03-31 19:08:59,477 [trainer.py] => weight_decay: 0.0
2024-03-31 19:08:59,477 [trainer.py] => rank: 10
2024-03-31 19:08:59,477 [trainer.py] => lamb: 0.95
2024-03-31 19:08:59,477 [trainer.py] => lame: 1.0
2024-03-31 19:08:59,477 [trainer.py] => num_workers: 16
2024-03-31 19:08:59,599 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
2024-03-31 19:09:03,649 [trainer.py] => All params: 111348451
2024-03-31 19:09:03,653 [trainer.py] => Trainable params: 111348451
2024-03-31 19:09:03,653 [inflora_ca.py] => Learning on 0-20
2024-03-31 19:27:08,643 [inflora_ca.py] => Task 0, Epoch 50/50 => Loss 0.284, Train_accy 91.24
2024-03-31 19:28:00,940 [trainer.py] => Time:1137.2870798110962
2024-03-31 19:28:34,238 [trainer.py] => Time:33.29736065864563
2024-03-31 19:28:34,238 [inflora_ca.py] => Exemplar size: 0
2024-03-31 19:28:34,239 [trainer.py] => CNN: {'total': 90.11, '00-19': 90.11, 'old': 0, 'new': 90.11}
2024-03-31 19:28:34,239 [trainer.py] => CNN top1 curve: [90.11]
2024-03-31 19:28:34,239 [trainer.py] => CNN top1 with task curve: [90.11]
2024-03-31 19:28:34,239 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 19:28:34,242 [trainer.py] => All params: 111348451
2024-03-31 19:28:34,244 [trainer.py] => Trainable params: 199700
2024-03-31 19:28:34,244 [inflora_ca.py] => Learning on 20-40
2024-03-31 19:48:58,159 [inflora_ca.py] => Task 1, Epoch 50/50 => Loss 0.313, Train_accy 91.06
2024-03-31 19:50:08,239 [inflora_ca.py] => CA Task 1 => Loss 0.123, Test_accy 86.360
2024-03-31 19:50:15,188 [inflora_ca.py] => CA Task 1 => Loss 0.073, Test_accy 87.300
2024-03-31 19:50:22,621 [inflora_ca.py] => CA Task 1 => Loss 0.054, Test_accy 87.660
2024-03-31 19:50:30,528 [inflora_ca.py] => CA Task 1 => Loss 0.046, Test_accy 87.300
2024-03-31 19:50:38,793 [inflora_ca.py] => CA Task 1 => Loss 0.044, Test_accy 87.160
2024-03-31 19:50:38,794 [trainer.py] => Time:1324.5492053031921
2024-03-31 19:51:41,161 [trainer.py] => Time:62.36750388145447
2024-03-31 19:51:41,161 [inflora_ca.py] => Exemplar size: 0
2024-03-31 19:51:41,161 [trainer.py] => CNN: {'total': 87.16, '00-19': 86.53, '20-39': 87.79, 'old': 86.53, 'new': 87.79}
2024-03-31 19:51:41,162 [trainer.py] => CNN top1 curve: [90.11, 87.16]
2024-03-31 19:51:41,162 [trainer.py] => CNN top1 with task curve: [90.11, 90.62]
2024-03-31 19:51:41,162 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365]
2024-03-31 19:51:41,164 [trainer.py] => All params: 111348451
2024-03-31 19:51:41,166 [trainer.py] => Trainable params: 215080
2024-03-31 19:51:41,166 [inflora_ca.py] => Learning on 40-60
2024-03-31 20:04:29,737 [inflora_ca.py] => Task 2, Epoch 50/50 => Loss 0.368, Train_accy 89.04
2024-03-31 20:05:27,691 [inflora_ca.py] => CA Task 2 => Loss 0.082, Test_accy 84.610
2024-03-31 20:05:36,502 [inflora_ca.py] => CA Task 2 => Loss 0.055, Test_accy 85.540
2024-03-31 20:05:46,821 [inflora_ca.py] => CA Task 2 => Loss 0.044, Test_accy 85.870
2024-03-31 20:05:57,299 [inflora_ca.py] => CA Task 2 => Loss 0.035, Test_accy 85.820
2024-03-31 20:06:07,123 [inflora_ca.py] => CA Task 2 => Loss 0.033, Test_accy 85.980
2024-03-31 20:06:07,124 [trainer.py] => Time:865.9581348896027
2024-03-31 20:07:20,005 [trainer.py] => Time:72.88066267967224
2024-03-31 20:07:20,005 [inflora_ca.py] => Exemplar size: 0
2024-03-31 20:07:20,005 [trainer.py] => CNN: {'total': 85.98, '00-19': 85.1, '20-39': 86.77, '40-59': 86.14, 'old': 85.93, 'new': 86.14}
2024-03-31 20:07:20,005 [trainer.py] => CNN top1 curve: [90.11, 87.16, 85.98]
2024-03-31 20:07:20,005 [trainer.py] => CNN top1 with task curve: [90.11, 90.62, 89.39]
2024-03-31 20:07:20,005 [trainer.py] => CNN top1 task curve: [1.0, 0.9365079365079365, 0.9334799340296867]
2024-03-31 20:07:20,008 [trainer.py] => All params: 111348451
2024-03-31 20:07:20,011 [trainer.py] => Trainable params: 230460
2024-03-31 20:07:20,011 [inflora_ca.py] => Learning on 60-80
