2024-03-31 08:16:06,446 [trainer.py] => config: configs/cifar100_inflora.json
2024-03-31 08:16:06,446 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 08:16:06,446 [trainer.py] => prefix: reproduce
2024-03-31 08:16:06,446 [trainer.py] => dataset: cifar100
2024-03-31 08:16:06,446 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 08:16:06,446 [trainer.py] => memory_size: 0
2024-03-31 08:16:06,446 [trainer.py] => memory_per_class: 0
2024-03-31 08:16:06,446 [trainer.py] => fixed_memory: True
2024-03-31 08:16:06,446 [trainer.py] => shuffle: False
2024-03-31 08:16:06,446 [trainer.py] => init_cls: 10
2024-03-31 08:16:06,446 [trainer.py] => increment: 10
2024-03-31 08:16:06,446 [trainer.py] => model_name: InfLoRA
2024-03-31 08:16:06,446 [trainer.py] => net_type: sip
2024-03-31 08:16:06,447 [trainer.py] => embd_dim: 768
2024-03-31 08:16:06,447 [trainer.py] => num_heads: 12
2024-03-31 08:16:06,447 [trainer.py] => total_sessions: 10
2024-03-31 08:16:06,447 [trainer.py] => seed: 0
2024-03-31 08:16:06,447 [trainer.py] => EPSILON: 1e-08
2024-03-31 08:16:06,447 [trainer.py] => init_epoch: 20
2024-03-31 08:16:06,447 [trainer.py] => optim: adam
2024-03-31 08:16:06,447 [trainer.py] => init_lr: 0.0005
2024-03-31 08:16:06,447 [trainer.py] => init_lr_decay: 0.1
2024-03-31 08:16:06,447 [trainer.py] => init_weight_decay: 0.0
2024-03-31 08:16:06,447 [trainer.py] => epochs: 20
2024-03-31 08:16:06,447 [trainer.py] => lrate: 0.0005
2024-03-31 08:16:06,447 [trainer.py] => lrate_decay: 0.1
2024-03-31 08:16:06,447 [trainer.py] => batch_size: 128
2024-03-31 08:16:06,447 [trainer.py] => weight_decay: 0.0
2024-03-31 08:16:06,447 [trainer.py] => rank: 10
2024-03-31 08:16:06,447 [trainer.py] => lamb: 0.95
2024-03-31 08:16:06,447 [trainer.py] => lame: 1.0
2024-03-31 08:16:06,447 [trainer.py] => num_workers: 16
2024-03-31 08:16:08,191 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 08:16:11,505 [trainer.py] => All params: 111194651
2024-03-31 08:16:11,508 [trainer.py] => Trainable params: 111194651
2024-03-31 08:16:11,508 [inflora.py] => Learning on 0-10
2024-03-31 08:16:20,004 [trainer.py] => config: configs/cifar100_inflora.json
2024-03-31 08:16:20,004 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 08:16:20,004 [trainer.py] => prefix: reproduce
2024-03-31 08:16:20,004 [trainer.py] => dataset: cifar100
2024-03-31 08:16:20,005 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 08:16:20,005 [trainer.py] => memory_size: 0
2024-03-31 08:16:20,005 [trainer.py] => memory_per_class: 0
2024-03-31 08:16:20,005 [trainer.py] => fixed_memory: True
2024-03-31 08:16:20,005 [trainer.py] => shuffle: False
2024-03-31 08:16:20,005 [trainer.py] => init_cls: 10
2024-03-31 08:16:20,005 [trainer.py] => increment: 10
2024-03-31 08:16:20,005 [trainer.py] => model_name: InfLoRA
2024-03-31 08:16:20,005 [trainer.py] => net_type: sip
2024-03-31 08:16:20,005 [trainer.py] => embd_dim: 768
2024-03-31 08:16:20,005 [trainer.py] => num_heads: 12
2024-03-31 08:16:20,005 [trainer.py] => total_sessions: 10
2024-03-31 08:16:20,005 [trainer.py] => seed: 0
2024-03-31 08:16:20,005 [trainer.py] => EPSILON: 1e-08
2024-03-31 08:16:20,005 [trainer.py] => init_epoch: 20
2024-03-31 08:16:20,005 [trainer.py] => optim: adam
2024-03-31 08:16:20,005 [trainer.py] => init_lr: 0.0005
2024-03-31 08:16:20,005 [trainer.py] => init_lr_decay: 0.1
2024-03-31 08:16:20,005 [trainer.py] => init_weight_decay: 0.0
2024-03-31 08:16:20,005 [trainer.py] => epochs: 20
2024-03-31 08:16:20,005 [trainer.py] => lrate: 0.0005
2024-03-31 08:16:20,005 [trainer.py] => lrate_decay: 0.1
2024-03-31 08:16:20,005 [trainer.py] => batch_size: 128
2024-03-31 08:16:20,005 [trainer.py] => weight_decay: 0.0
2024-03-31 08:16:20,005 [trainer.py] => rank: 10
2024-03-31 08:16:20,005 [trainer.py] => lamb: 0.95
2024-03-31 08:16:20,005 [trainer.py] => lame: 1.0
2024-03-31 08:16:20,005 [trainer.py] => num_workers: 16
2024-03-31 08:16:21,588 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 08:16:24,119 [trainer.py] => All params: 111194651
2024-03-31 08:16:24,122 [trainer.py] => Trainable params: 111194651
2024-03-31 08:16:24,122 [inflora.py] => Learning on 0-10
2024-03-31 08:30:02,039 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.091, Train_accy 96.86
2024-03-31 08:30:28,489 [inflora.py] => Layer 1 : 6/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 2 : 9/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 3 : 11/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 4 : 10/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 5 : 13/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 6 : 14/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 7 : 14/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 8 : 18/768
2024-03-31 08:30:28,490 [inflora.py] => Layer 9 : 20/768
2024-03-31 08:30:28,491 [inflora.py] => Layer 10 : 17/768
2024-03-31 08:30:28,491 [inflora.py] => Layer 11 : 7/768
2024-03-31 08:30:28,491 [inflora.py] => Layer 12 : 11/768
2024-03-31 08:30:50,416 [trainer.py] => Time:866.2940061092377
2024-03-31 08:30:56,432 [trainer.py] => Time:6.016139030456543
2024-03-31 08:30:56,433 [inflora.py] => Exemplar size: 0
2024-03-31 08:30:56,433 [trainer.py] => CNN: {'total': 99.4, '00-09': 99.4, 'old': 0, 'new': 99.4}
2024-03-31 08:30:56,433 [trainer.py] => CNN top1 curve: [99.4]
2024-03-31 08:30:56,433 [trainer.py] => CNN top1 with task curve: [99.4]
2024-03-31 08:30:56,433 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 08:30:56,436 [trainer.py] => All params: 111194651
2024-03-31 08:30:56,439 [trainer.py] => Trainable params: 192010
2024-03-31 08:30:56,439 [inflora.py] => Learning on 10-20
2024-03-31 08:44:35,196 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.133, Train_accy 95.62
2024-03-31 08:45:04,066 [inflora.py] => Layer 1 : 7/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 2 : 11/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 3 : 13/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 4 : 13/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 5 : 18/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 6 : 21/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 7 : 21/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 8 : 29/768
2024-03-31 08:45:04,066 [inflora.py] => Layer 9 : 41/768
2024-03-31 08:45:04,067 [inflora.py] => Layer 10 : 42/768
2024-03-31 08:45:04,067 [inflora.py] => Layer 11 : 14/768
2024-03-31 08:45:04,067 [inflora.py] => Layer 12 : 25/768
2024-03-31 08:45:26,994 [trainer.py] => Time:870.5550270080566
2024-03-31 08:45:41,456 [trainer.py] => Time:14.461186170578003
2024-03-31 08:45:41,456 [inflora.py] => Exemplar size: 0
2024-03-31 08:45:41,456 [trainer.py] => CNN: {'total': 96.55, '00-09': 98.1, '10-19': 95.0, 'old': 98.1, 'new': 95.0}
2024-03-31 08:45:41,456 [trainer.py] => CNN top1 curve: [99.4, 96.55]
2024-03-31 08:45:41,456 [trainer.py] => CNN top1 with task curve: [99.4, 99.15]
2024-03-31 08:45:41,456 [trainer.py] => CNN top1 task curve: [1.0, 0.9725]
2024-03-31 08:45:41,460 [trainer.py] => All params: 111194651
2024-03-31 08:45:41,464 [trainer.py] => Trainable params: 192010
2024-03-31 08:45:41,464 [inflora.py] => Learning on 20-30
2024-03-31 08:59:28,159 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.135, Train_accy 95.66
2024-03-31 08:59:55,532 [inflora.py] => Layer 1 : 7/768
2024-03-31 08:59:55,532 [inflora.py] => Layer 2 : 11/768
2024-03-31 08:59:55,532 [inflora.py] => Layer 3 : 14/768
2024-03-31 08:59:55,532 [inflora.py] => Layer 4 : 16/768
2024-03-31 08:59:55,532 [inflora.py] => Layer 5 : 22/768
2024-03-31 08:59:55,532 [inflora.py] => Layer 6 : 25/768
2024-03-31 08:59:55,533 [inflora.py] => Layer 7 : 28/768
2024-03-31 08:59:55,533 [inflora.py] => Layer 8 : 40/768
2024-03-31 08:59:55,533 [inflora.py] => Layer 9 : 58/768
2024-03-31 08:59:55,533 [inflora.py] => Layer 10 : 56/768
2024-03-31 08:59:55,533 [inflora.py] => Layer 11 : 20/768
2024-03-31 08:59:55,533 [inflora.py] => Layer 12 : 35/768
2024-03-31 09:00:16,577 [trainer.py] => Time:875.1135895252228
2024-03-31 09:00:32,404 [trainer.py] => Time:15.82590937614441
2024-03-31 09:00:32,404 [inflora.py] => Exemplar size: 0
2024-03-31 09:00:32,405 [trainer.py] => CNN: {'total': 94.47, '00-09': 97.4, '10-19': 93.3, '20-29': 92.7, 'old': 95.35, 'new': 92.7}
2024-03-31 09:00:32,405 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47]
2024-03-31 09:00:32,405 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8]
2024-03-31 09:00:32,405 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334]
2024-03-31 09:00:32,411 [trainer.py] => All params: 111194651
2024-03-31 09:00:32,416 [trainer.py] => Trainable params: 192010
2024-03-31 09:00:32,417 [inflora.py] => Learning on 30-40
2024-03-31 09:14:18,033 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.120, Train_accy 96.08
2024-03-31 09:14:51,558 [inflora.py] => Layer 1 : 7/768
2024-03-31 09:14:51,564 [inflora.py] => Layer 2 : 12/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 3 : 17/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 4 : 19/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 5 : 25/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 6 : 30/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 7 : 35/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 8 : 53/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 9 : 84/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 10 : 86/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 11 : 33/768
2024-03-31 09:14:51,565 [inflora.py] => Layer 12 : 46/768
2024-03-31 09:15:14,835 [trainer.py] => Time:882.4179835319519
2024-03-31 09:15:37,075 [trainer.py] => Time:22.24042773246765
2024-03-31 09:15:37,076 [inflora.py] => Exemplar size: 0
2024-03-31 09:15:37,076 [trainer.py] => CNN: {'total': 92.1, '00-09': 97.2, '10-19': 89.7, '20-29': 92.3, '30-39': 89.2, 'old': 93.07, 'new': 89.2}
2024-03-31 09:15:37,076 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1]
2024-03-31 09:15:37,076 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62]
2024-03-31 09:15:37,076 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775]
2024-03-31 09:15:37,080 [trainer.py] => All params: 111194651
2024-03-31 09:15:37,084 [trainer.py] => Trainable params: 192010
2024-03-31 09:15:37,084 [inflora.py] => Learning on 40-50
2024-03-31 09:29:25,263 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.129, Train_accy 95.76
2024-03-31 09:29:52,448 [inflora.py] => Layer 1 : 7/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 2 : 13/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 3 : 19/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 4 : 22/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 5 : 30/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 6 : 36/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 7 : 41/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 8 : 61/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 9 : 96/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 10 : 102/768
2024-03-31 09:29:52,449 [inflora.py] => Layer 11 : 41/768
2024-03-31 09:29:52,450 [inflora.py] => Layer 12 : 58/768
2024-03-31 09:30:11,613 [trainer.py] => Time:874.529378414154
2024-03-31 09:30:39,438 [trainer.py] => Time:27.824764013290405
2024-03-31 09:30:39,439 [inflora.py] => Exemplar size: 0
2024-03-31 09:30:39,439 [trainer.py] => CNN: {'total': 90.98, '00-09': 95.5, '10-19': 88.2, '20-29': 90.9, '30-39': 86.6, '40-49': 93.7, 'old': 90.3, 'new': 93.7}
2024-03-31 09:30:39,439 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98]
2024-03-31 09:30:39,439 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66]
2024-03-31 09:30:39,439 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916]
2024-03-31 09:30:39,441 [trainer.py] => All params: 111194651
2024-03-31 09:30:39,443 [trainer.py] => Trainable params: 192010
2024-03-31 09:30:39,443 [inflora.py] => Learning on 50-60
2024-03-31 09:44:21,431 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.126, Train_accy 95.50
2024-03-31 09:44:48,033 [inflora.py] => Layer 1 : 7/768
2024-03-31 09:44:48,033 [inflora.py] => Layer 2 : 14/768
2024-03-31 09:44:48,033 [inflora.py] => Layer 3 : 20/768
2024-03-31 09:44:48,033 [inflora.py] => Layer 4 : 26/768
2024-03-31 09:44:48,033 [inflora.py] => Layer 5 : 35/768
2024-03-31 09:44:48,033 [inflora.py] => Layer 6 : 45/768
2024-03-31 09:44:48,033 [inflora.py] => Layer 7 : 52/768
2024-03-31 09:44:48,034 [inflora.py] => Layer 8 : 83/768
2024-03-31 09:44:48,034 [inflora.py] => Layer 9 : 120/768
2024-03-31 09:44:48,034 [inflora.py] => Layer 10 : 124/768
2024-03-31 09:44:48,034 [inflora.py] => Layer 11 : 52/768
2024-03-31 09:44:48,034 [inflora.py] => Layer 12 : 70/768
2024-03-31 09:45:09,280 [trainer.py] => Time:869.8375723361969
2024-03-31 09:45:42,506 [trainer.py] => Time:33.225175857543945
2024-03-31 09:45:42,506 [inflora.py] => Exemplar size: 0
2024-03-31 09:45:42,506 [trainer.py] => CNN: {'total': 89.05, '00-09': 94.2, '10-19': 87.8, '20-29': 90.5, '30-39': 86.6, '40-49': 93.2, '50-59': 82.0, 'old': 90.46, 'new': 82.0}
2024-03-31 09:45:42,506 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05]
2024-03-31 09:45:42,506 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52]
2024-03-31 09:45:42,506 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896]
2024-03-31 09:45:42,508 [trainer.py] => All params: 111194651
2024-03-31 09:45:42,510 [trainer.py] => Trainable params: 192010
2024-03-31 09:45:42,510 [inflora.py] => Learning on 60-70
2024-03-31 09:59:30,599 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.128, Train_accy 95.88
2024-03-31 09:59:58,440 [inflora.py] => Layer 1 : 8/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 2 : 15/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 3 : 22/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 4 : 30/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 5 : 40/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 6 : 54/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 7 : 65/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 8 : 100/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 9 : 141/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 10 : 148/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 11 : 68/768
2024-03-31 09:59:58,440 [inflora.py] => Layer 12 : 87/768
2024-03-31 10:00:19,299 [trainer.py] => Time:876.7887582778931
2024-03-31 10:00:57,461 [trainer.py] => Time:38.161356687545776
2024-03-31 10:00:57,461 [inflora.py] => Exemplar size: 0
2024-03-31 10:00:57,461 [trainer.py] => CNN: {'total': 88.31, '00-09': 94.1, '10-19': 86.1, '20-29': 89.5, '30-39': 87.1, '40-49': 93.1, '50-59': 81.5, '60-69': 86.8, 'old': 88.57, 'new': 86.8}
2024-03-31 10:00:57,461 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31]
2024-03-31 10:00:57,461 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5]
2024-03-31 10:00:57,461 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715]
2024-03-31 10:00:57,463 [trainer.py] => All params: 111194651
2024-03-31 10:00:57,465 [trainer.py] => Trainable params: 192010
2024-03-31 10:00:57,465 [inflora.py] => Learning on 70-80
2024-03-31 10:14:47,659 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.125, Train_accy 95.68
2024-03-31 10:15:15,518 [inflora.py] => Layer 1 : 9/768
2024-03-31 10:15:15,518 [inflora.py] => Layer 2 : 17/768
2024-03-31 10:15:15,518 [inflora.py] => Layer 3 : 25/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 4 : 35/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 5 : 49/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 6 : 68/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 7 : 84/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 8 : 134/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 9 : 193/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 10 : 204/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 11 : 96/768
2024-03-31 10:15:15,519 [inflora.py] => Layer 12 : 117/768
2024-03-31 10:15:36,419 [trainer.py] => Time:878.9545588493347
2024-03-31 10:16:19,294 [trainer.py] => Time:42.8742790222168
2024-03-31 10:16:19,294 [inflora.py] => Exemplar size: 0
2024-03-31 10:16:19,294 [trainer.py] => CNN: {'total': 87.76, '00-09': 93.6, '10-19': 85.5, '20-29': 88.9, '30-39': 86.1, '40-49': 93.3, '50-59': 80.3, '60-69': 85.4, '70-79': 89.0, 'old': 87.59, 'new': 89.0}
2024-03-31 10:16:19,294 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31, 87.76]
2024-03-31 10:16:19,295 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5, 98.3]
2024-03-31 10:16:19,295 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715, 0.881875]
2024-03-31 10:16:19,299 [trainer.py] => All params: 111194651
2024-03-31 10:16:19,303 [trainer.py] => Trainable params: 192010
2024-03-31 10:16:19,303 [inflora.py] => Learning on 80-90
2024-03-31 10:30:08,586 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.106, Train_accy 96.32
2024-03-31 10:30:34,247 [inflora.py] => Layer 1 : 9/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 2 : 21/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 3 : 33/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 4 : 47/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 5 : 67/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 6 : 99/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 7 : 118/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 8 : 175/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 9 : 253/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 10 : 290/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 11 : 182/768
2024-03-31 10:30:34,247 [inflora.py] => Layer 12 : 192/768
2024-03-31 10:30:53,589 [trainer.py] => Time:874.2862195968628
2024-03-31 10:31:45,772 [trainer.py] => Time:52.18222999572754
2024-03-31 10:31:45,772 [inflora.py] => Exemplar size: 0
2024-03-31 10:31:45,772 [trainer.py] => CNN: {'total': 87.93, '00-09': 93.7, '10-19': 85.0, '20-29': 88.6, '30-39': 86.1, '40-49': 92.3, '50-59': 79.9, '60-69': 85.4, '70-79': 86.9, '80-89': 93.5, 'old': 87.24, 'new': 93.5}
2024-03-31 10:31:45,772 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31, 87.76, 87.93]
2024-03-31 10:31:45,772 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5, 98.3, 98.4]
2024-03-31 10:31:45,772 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715, 0.881875, 0.8833333333333333]
2024-03-31 10:31:45,774 [trainer.py] => All params: 111194651
2024-03-31 10:31:45,776 [trainer.py] => Trainable params: 192010
2024-03-31 10:31:45,776 [inflora.py] => Learning on 90-100
2024-03-31 10:41:20,959 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.080, Train_accy 97.50
2024-03-31 10:41:45,419 [inflora.py] => Layer 1 : 10/768
2024-03-31 10:41:45,419 [inflora.py] => Layer 2 : 24/768
2024-03-31 10:41:45,419 [inflora.py] => Layer 3 : 44/768
2024-03-31 10:41:45,419 [inflora.py] => Layer 4 : 67/768
2024-03-31 10:41:45,419 [inflora.py] => Layer 5 : 95/768
2024-03-31 10:41:45,419 [inflora.py] => Layer 6 : 142/768
2024-03-31 10:41:45,420 [inflora.py] => Layer 7 : 182/768
2024-03-31 10:41:45,420 [inflora.py] => Layer 8 : 264/768
2024-03-31 10:41:45,420 [inflora.py] => Layer 9 : 359/768
2024-03-31 10:41:45,420 [inflora.py] => Layer 10 : 410/768
2024-03-31 10:41:45,420 [inflora.py] => Layer 11 : 307/768
2024-03-31 10:41:45,420 [inflora.py] => Layer 12 : 325/768
2024-03-31 10:41:59,740 [trainer.py] => Time:613.9638004302979
2024-03-31 10:42:21,370 [trainer.py] => Time:21.630030393600464
2024-03-31 10:42:21,370 [inflora.py] => Exemplar size: 0
2024-03-31 10:42:21,370 [trainer.py] => CNN: {'total': 86.34, '00-09': 92.7, '10-19': 84.8, '20-29': 88.1, '30-39': 84.4, '40-49': 90.8, '50-59': 77.7, '60-69': 84.0, '70-79': 86.9, '80-89': 93.1, '90-99': 80.9, 'old': 86.94, 'new': 80.9}
2024-03-31 10:42:21,370 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31, 87.76, 87.93, 86.34]
2024-03-31 10:42:21,371 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5, 98.3, 98.4, 98.49]
2024-03-31 10:42:21,371 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715, 0.881875, 0.8833333333333333, 0.8676]
2024-03-31 11:03:28,035 [trainer.py] => config: configs/cifar100_inflora.json
2024-03-31 11:03:28,035 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 11:03:28,035 [trainer.py] => prefix: reproduce
2024-03-31 11:03:28,035 [trainer.py] => dataset: cifar100
2024-03-31 11:03:28,035 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 11:03:28,035 [trainer.py] => memory_size: 0
2024-03-31 11:03:28,035 [trainer.py] => memory_per_class: 0
2024-03-31 11:03:28,035 [trainer.py] => fixed_memory: True
2024-03-31 11:03:28,036 [trainer.py] => shuffle: False
2024-03-31 11:03:28,036 [trainer.py] => init_cls: 10
2024-03-31 11:03:28,036 [trainer.py] => increment: 10
2024-03-31 11:03:28,036 [trainer.py] => model_name: InfLoRA
2024-03-31 11:03:28,036 [trainer.py] => net_type: sip
2024-03-31 11:03:28,036 [trainer.py] => embd_dim: 768
2024-03-31 11:03:28,036 [trainer.py] => num_heads: 12
2024-03-31 11:03:28,036 [trainer.py] => total_sessions: 10
2024-03-31 11:03:28,036 [trainer.py] => seed: 0
2024-03-31 11:03:28,036 [trainer.py] => EPSILON: 1e-08
2024-03-31 11:03:28,036 [trainer.py] => init_epoch: 20
2024-03-31 11:03:28,036 [trainer.py] => optim: adam
2024-03-31 11:03:28,036 [trainer.py] => init_lr: 0.0005
2024-03-31 11:03:28,036 [trainer.py] => init_lr_decay: 0.1
2024-03-31 11:03:28,036 [trainer.py] => init_weight_decay: 0.0
2024-03-31 11:03:28,036 [trainer.py] => epochs: 20
2024-03-31 11:03:28,036 [trainer.py] => lrate: 0.0005
2024-03-31 11:03:28,036 [trainer.py] => lrate_decay: 0.1
2024-03-31 11:03:28,036 [trainer.py] => batch_size: 128
2024-03-31 11:03:28,036 [trainer.py] => weight_decay: 0.0
2024-03-31 11:03:28,036 [trainer.py] => rank: 10
2024-03-31 11:03:28,036 [trainer.py] => lamb: 0.95
2024-03-31 11:03:28,036 [trainer.py] => lame: 1.0
2024-03-31 11:03:28,036 [trainer.py] => num_workers: 16
2024-03-31 20:18:16,644 [trainer.py] => config: configs/cifar100_inflora.json
2024-03-31 20:18:16,644 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 20:18:16,644 [trainer.py] => prefix: reproduce
2024-03-31 20:18:16,644 [trainer.py] => dataset: cifar100
2024-03-31 20:18:16,644 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 20:18:16,644 [trainer.py] => memory_size: 0
2024-03-31 20:18:16,645 [trainer.py] => memory_per_class: 0
2024-03-31 20:18:16,645 [trainer.py] => fixed_memory: True
2024-03-31 20:18:16,645 [trainer.py] => shuffle: False
2024-03-31 20:18:16,645 [trainer.py] => init_cls: 10
2024-03-31 20:18:16,645 [trainer.py] => increment: 10
2024-03-31 20:18:16,645 [trainer.py] => model_name: InfLoRA
2024-03-31 20:18:16,645 [trainer.py] => net_type: sip
2024-03-31 20:18:16,645 [trainer.py] => embd_dim: 768
2024-03-31 20:18:16,645 [trainer.py] => num_heads: 12
2024-03-31 20:18:16,645 [trainer.py] => total_sessions: 10
2024-03-31 20:18:16,645 [trainer.py] => seed: 0
2024-03-31 20:18:16,645 [trainer.py] => EPSILON: 1e-08
2024-03-31 20:18:16,645 [trainer.py] => init_epoch: 20
2024-03-31 20:18:16,645 [trainer.py] => optim: adam
2024-03-31 20:18:16,645 [trainer.py] => init_lr: 0.0005
2024-03-31 20:18:16,645 [trainer.py] => init_lr_decay: 0.1
2024-03-31 20:18:16,645 [trainer.py] => init_weight_decay: 0.0
2024-03-31 20:18:16,645 [trainer.py] => epochs: 20
2024-03-31 20:18:16,645 [trainer.py] => lrate: 0.0005
2024-03-31 20:18:16,645 [trainer.py] => lrate_decay: 0.1
2024-03-31 20:18:16,645 [trainer.py] => batch_size: 128
2024-03-31 20:18:16,645 [trainer.py] => weight_decay: 0.0
2024-03-31 20:18:16,645 [trainer.py] => rank: 10
2024-03-31 20:18:16,645 [trainer.py] => lamb: 0.95
2024-03-31 20:18:16,645 [trainer.py] => lame: 1.0
2024-03-31 20:18:16,645 [trainer.py] => num_workers: 16
2024-03-31 20:18:18,253 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 20:18:21,891 [trainer.py] => All params: 111194651
2024-03-31 20:18:21,894 [trainer.py] => Trainable params: 111194651
2024-03-31 20:18:21,894 [inflora.py] => Learning on 0-10
2024-03-31 20:31:33,926 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.091, Train_accy 96.86
2024-03-31 20:32:19,560 [trainer.py] => Time:837.6652619838715
2024-03-31 20:32:27,136 [trainer.py] => Time:7.575751781463623
2024-03-31 20:32:27,136 [inflora.py] => Exemplar size: 0
2024-03-31 20:32:27,136 [trainer.py] => CNN: {'total': 99.4, '00-09': 99.4, 'old': 0, 'new': 99.4}
2024-03-31 20:32:27,136 [trainer.py] => CNN top1 curve: [99.4]
2024-03-31 20:32:27,136 [trainer.py] => CNN top1 with task curve: [99.4]
2024-03-31 20:32:27,136 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 20:32:27,139 [trainer.py] => All params: 111194651
2024-03-31 20:32:27,141 [trainer.py] => Trainable params: 192010
2024-03-31 20:32:27,141 [inflora.py] => Learning on 10-20
2024-03-31 20:34:07,280 [trainer.py] => config: configs/cifar100_inflora.json
2024-03-31 20:34:07,280 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 20:34:07,280 [trainer.py] => prefix: reproduce
2024-03-31 20:34:07,280 [trainer.py] => dataset: cifar100
2024-03-31 20:34:07,280 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 20:34:07,280 [trainer.py] => memory_size: 0
2024-03-31 20:34:07,280 [trainer.py] => memory_per_class: 0
2024-03-31 20:34:07,280 [trainer.py] => fixed_memory: True
2024-03-31 20:34:07,280 [trainer.py] => shuffle: False
2024-03-31 20:34:07,280 [trainer.py] => init_cls: 10
2024-03-31 20:34:07,280 [trainer.py] => increment: 10
2024-03-31 20:34:07,280 [trainer.py] => model_name: InfLoRA
2024-03-31 20:34:07,280 [trainer.py] => net_type: sip
2024-03-31 20:34:07,280 [trainer.py] => embd_dim: 768
2024-03-31 20:34:07,280 [trainer.py] => num_heads: 12
2024-03-31 20:34:07,280 [trainer.py] => total_sessions: 10
2024-03-31 20:34:07,280 [trainer.py] => seed: 0
2024-03-31 20:34:07,280 [trainer.py] => EPSILON: 1e-08
2024-03-31 20:34:07,280 [trainer.py] => init_epoch: 20
2024-03-31 20:34:07,280 [trainer.py] => optim: adam
2024-03-31 20:34:07,280 [trainer.py] => init_lr: 0.0005
2024-03-31 20:34:07,280 [trainer.py] => init_lr_decay: 0.1
2024-03-31 20:34:07,280 [trainer.py] => init_weight_decay: 0.0
2024-03-31 20:34:07,280 [trainer.py] => epochs: 20
2024-03-31 20:34:07,280 [trainer.py] => lrate: 0.0005
2024-03-31 20:34:07,280 [trainer.py] => lrate_decay: 0.1
2024-03-31 20:34:07,280 [trainer.py] => batch_size: 128
2024-03-31 20:34:07,280 [trainer.py] => weight_decay: 0.0
2024-03-31 20:34:07,280 [trainer.py] => rank: 10
2024-03-31 20:34:07,280 [trainer.py] => lamb: 0.95
2024-03-31 20:34:07,280 [trainer.py] => lame: 1.0
2024-03-31 20:34:07,281 [trainer.py] => num_workers: 16
2024-03-31 20:34:08,873 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 20:34:12,234 [trainer.py] => All params: 111194651
2024-03-31 20:34:12,237 [trainer.py] => Trainable params: 111194651
2024-03-31 20:34:12,237 [inflora.py] => Learning on 0-10
2024-03-31 20:47:28,165 [inflora.py] => Task 0, Epoch 20/20 => Loss 0.091, Train_accy 96.86
2024-03-31 20:48:09,550 [trainer.py] => Time:837.3126995563507
2024-03-31 20:48:15,483 [trainer.py] => Time:5.933007001876831
2024-03-31 20:48:15,484 [inflora.py] => Exemplar size: 0
2024-03-31 20:48:15,484 [trainer.py] => CNN: {'total': 99.4, '00-09': 99.4, 'old': 0, 'new': 99.4}
2024-03-31 20:48:15,484 [trainer.py] => CNN top1 curve: [99.4]
2024-03-31 20:48:15,484 [trainer.py] => CNN top1 with task curve: [99.4]
2024-03-31 20:48:15,484 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 20:48:15,487 [trainer.py] => All params: 111194651
2024-03-31 20:48:15,490 [trainer.py] => Trainable params: 192010
2024-03-31 20:48:15,490 [inflora.py] => Learning on 10-20
2024-03-31 21:01:35,008 [inflora.py] => Task 1, Epoch 20/20 => Loss 0.133, Train_accy 95.62
2024-03-31 21:02:22,411 [trainer.py] => Time:846.9216318130493
2024-03-31 21:02:35,823 [trainer.py] => Time:13.411564350128174
2024-03-31 21:02:35,824 [inflora.py] => Exemplar size: 0
2024-03-31 21:02:35,824 [trainer.py] => CNN: {'total': 96.55, '00-09': 98.1, '10-19': 95.0, 'old': 98.1, 'new': 95.0}
2024-03-31 21:02:35,824 [trainer.py] => CNN top1 curve: [99.4, 96.55]
2024-03-31 21:02:35,824 [trainer.py] => CNN top1 with task curve: [99.4, 99.15]
2024-03-31 21:02:35,824 [trainer.py] => CNN top1 task curve: [1.0, 0.9725]
2024-03-31 21:02:35,830 [trainer.py] => All params: 111194651
2024-03-31 21:02:35,836 [trainer.py] => Trainable params: 192010
2024-03-31 21:02:35,836 [inflora.py] => Learning on 20-30
2024-03-31 21:15:49,701 [inflora.py] => Task 2, Epoch 20/20 => Loss 0.135, Train_accy 95.66
2024-03-31 21:16:34,838 [trainer.py] => Time:839.0016987323761
2024-03-31 21:16:49,534 [trainer.py] => Time:14.696243047714233
2024-03-31 21:16:49,534 [inflora.py] => Exemplar size: 0
2024-03-31 21:16:49,535 [trainer.py] => CNN: {'total': 94.47, '00-09': 97.4, '10-19': 93.3, '20-29': 92.7, 'old': 95.35, 'new': 92.7}
2024-03-31 21:16:49,535 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47]
2024-03-31 21:16:49,535 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8]
2024-03-31 21:16:49,535 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334]
2024-03-31 21:16:49,539 [trainer.py] => All params: 111194651
2024-03-31 21:16:49,542 [trainer.py] => Trainable params: 192010
2024-03-31 21:16:49,543 [inflora.py] => Learning on 30-40
2024-03-31 21:29:33,149 [inflora.py] => Task 3, Epoch 20/20 => Loss 0.120, Train_accy 96.08
2024-03-31 21:30:19,253 [trainer.py] => Time:809.7105424404144
2024-03-31 21:30:39,397 [trainer.py] => Time:20.143905878067017
2024-03-31 21:30:39,398 [inflora.py] => Exemplar size: 0
2024-03-31 21:30:39,398 [trainer.py] => CNN: {'total': 92.1, '00-09': 97.2, '10-19': 89.7, '20-29': 92.3, '30-39': 89.2, 'old': 93.07, 'new': 89.2}
2024-03-31 21:30:39,398 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1]
2024-03-31 21:30:39,398 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62]
2024-03-31 21:30:39,398 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775]
2024-03-31 21:30:39,401 [trainer.py] => All params: 111194651
2024-03-31 21:30:39,403 [trainer.py] => Trainable params: 192010
2024-03-31 21:30:39,403 [inflora.py] => Learning on 40-50
2024-03-31 21:43:55,558 [inflora.py] => Task 4, Epoch 20/20 => Loss 0.129, Train_accy 95.76
2024-03-31 21:44:39,605 [trainer.py] => Time:840.202737569809
2024-03-31 21:45:02,722 [trainer.py] => Time:23.11654829978943
2024-03-31 21:45:02,723 [inflora.py] => Exemplar size: 0
2024-03-31 21:45:02,723 [trainer.py] => CNN: {'total': 90.98, '00-09': 95.5, '10-19': 88.2, '20-29': 90.9, '30-39': 86.6, '40-49': 93.7, 'old': 90.3, 'new': 93.7}
2024-03-31 21:45:02,723 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98]
2024-03-31 21:45:02,723 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66]
2024-03-31 21:45:02,723 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916]
2024-03-31 21:45:02,725 [trainer.py] => All params: 111194651
2024-03-31 21:45:02,727 [trainer.py] => Trainable params: 192010
2024-03-31 21:45:02,727 [inflora.py] => Learning on 50-60
2024-03-31 21:58:20,093 [inflora.py] => Task 5, Epoch 20/20 => Loss 0.126, Train_accy 95.50
2024-03-31 21:59:08,393 [trainer.py] => Time:845.6660604476929
2024-03-31 21:59:41,554 [trainer.py] => Time:33.15992498397827
2024-03-31 21:59:41,554 [inflora.py] => Exemplar size: 0
2024-03-31 21:59:41,554 [trainer.py] => CNN: {'total': 89.05, '00-09': 94.2, '10-19': 87.8, '20-29': 90.5, '30-39': 86.6, '40-49': 93.2, '50-59': 82.0, 'old': 90.46, 'new': 82.0}
2024-03-31 21:59:41,554 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05]
2024-03-31 21:59:41,554 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52]
2024-03-31 21:59:41,554 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896]
2024-03-31 21:59:41,557 [trainer.py] => All params: 111194651
2024-03-31 21:59:41,560 [trainer.py] => Trainable params: 192010
2024-03-31 21:59:41,560 [inflora.py] => Learning on 60-70
2024-03-31 22:13:04,492 [inflora.py] => Task 6, Epoch 20/20 => Loss 0.128, Train_accy 95.88
2024-03-31 22:13:50,520 [trainer.py] => Time:848.9604640007019
2024-03-31 22:14:24,993 [trainer.py] => Time:34.47206735610962
2024-03-31 22:14:24,993 [inflora.py] => Exemplar size: 0
2024-03-31 22:14:24,993 [trainer.py] => CNN: {'total': 88.31, '00-09': 94.1, '10-19': 86.1, '20-29': 89.5, '30-39': 87.1, '40-49': 93.1, '50-59': 81.5, '60-69': 86.8, 'old': 88.57, 'new': 86.8}
2024-03-31 22:14:24,993 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31]
2024-03-31 22:14:24,993 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5]
2024-03-31 22:14:24,993 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715]
2024-03-31 22:14:24,995 [trainer.py] => All params: 111194651
2024-03-31 22:14:24,997 [trainer.py] => Trainable params: 192010
2024-03-31 22:14:24,997 [inflora.py] => Learning on 70-80
2024-03-31 22:27:45,944 [inflora.py] => Task 7, Epoch 20/20 => Loss 0.125, Train_accy 95.68
2024-03-31 22:28:31,774 [trainer.py] => Time:846.7776339054108
2024-03-31 22:29:11,533 [trainer.py] => Time:39.75871706008911
2024-03-31 22:29:11,533 [inflora.py] => Exemplar size: 0
2024-03-31 22:29:11,534 [trainer.py] => CNN: {'total': 87.76, '00-09': 93.6, '10-19': 85.5, '20-29': 88.9, '30-39': 86.1, '40-49': 93.3, '50-59': 80.3, '60-69': 85.4, '70-79': 89.0, 'old': 87.59, 'new': 89.0}
2024-03-31 22:29:11,534 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31, 87.76]
2024-03-31 22:29:11,534 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5, 98.3]
2024-03-31 22:29:11,534 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715, 0.881875]
2024-03-31 22:29:11,536 [trainer.py] => All params: 111194651
2024-03-31 22:29:11,537 [trainer.py] => Trainable params: 192010
2024-03-31 22:29:11,537 [inflora.py] => Learning on 80-90
2024-03-31 22:42:17,039 [inflora.py] => Task 8, Epoch 20/20 => Loss 0.106, Train_accy 96.32
2024-03-31 22:43:03,309 [trainer.py] => Time:831.7716982364655
2024-03-31 22:43:45,664 [trainer.py] => Time:42.354050397872925
2024-03-31 22:43:45,664 [inflora.py] => Exemplar size: 0
2024-03-31 22:43:45,664 [trainer.py] => CNN: {'total': 87.93, '00-09': 93.7, '10-19': 85.0, '20-29': 88.6, '30-39': 86.1, '40-49': 92.3, '50-59': 79.9, '60-69': 85.4, '70-79': 86.9, '80-89': 93.5, 'old': 87.24, 'new': 93.5}
2024-03-31 22:43:45,664 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31, 87.76, 87.93]
2024-03-31 22:43:45,664 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5, 98.3, 98.4]
2024-03-31 22:43:45,664 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715, 0.881875, 0.8833333333333333]
2024-03-31 22:43:45,666 [trainer.py] => All params: 111194651
2024-03-31 22:43:45,668 [trainer.py] => Trainable params: 192010
2024-03-31 22:43:45,668 [inflora.py] => Learning on 90-100
2024-03-31 22:56:39,400 [inflora.py] => Task 9, Epoch 20/20 => Loss 0.080, Train_accy 97.50
2024-03-31 22:57:23,669 [trainer.py] => Time:818.0012629032135
2024-03-31 22:58:12,368 [trainer.py] => Time:48.698301792144775
2024-03-31 22:58:12,368 [inflora.py] => Exemplar size: 0
2024-03-31 22:58:12,368 [trainer.py] => CNN: {'total': 86.34, '00-09': 92.7, '10-19': 84.8, '20-29': 88.1, '30-39': 84.4, '40-49': 90.8, '50-59': 77.7, '60-69': 84.0, '70-79': 86.9, '80-89': 93.1, '90-99': 80.9, 'old': 86.94, 'new': 80.9}
2024-03-31 22:58:12,369 [trainer.py] => CNN top1 curve: [99.4, 96.55, 94.47, 92.1, 90.98, 89.05, 88.31, 87.76, 87.93, 86.34]
2024-03-31 22:58:12,369 [trainer.py] => CNN top1 with task curve: [99.4, 99.15, 98.8, 98.62, 98.66, 98.52, 98.5, 98.3, 98.4, 98.49]
2024-03-31 22:58:12,369 [trainer.py] => CNN top1 task curve: [1.0, 0.9725, 0.9523333333333334, 0.92775, 0.916, 0.896, 0.8874285714285715, 0.881875, 0.8833333333333333, 0.8676]
