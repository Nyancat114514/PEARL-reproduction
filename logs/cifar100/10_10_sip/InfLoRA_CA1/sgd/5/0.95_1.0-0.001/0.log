2024-03-31 11:05:09,563 [trainer.py] => config: configs/cifar100_infloraca.json
2024-03-31 11:05:09,563 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 11:05:09,563 [trainer.py] => prefix: reproduce
2024-03-31 11:05:09,563 [trainer.py] => dataset: cifar100
2024-03-31 11:05:09,563 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 11:05:09,563 [trainer.py] => memory_size: 0
2024-03-31 11:05:09,563 [trainer.py] => memory_per_class: 0
2024-03-31 11:05:09,563 [trainer.py] => fixed_memory: True
2024-03-31 11:05:09,563 [trainer.py] => shuffle: False
2024-03-31 11:05:09,563 [trainer.py] => init_cls: 10
2024-03-31 11:05:09,563 [trainer.py] => increment: 10
2024-03-31 11:05:09,563 [trainer.py] => model_name: InfLoRA_CA1
2024-03-31 11:05:09,564 [trainer.py] => net_type: sip
2024-03-31 11:05:09,564 [trainer.py] => embd_dim: 768
2024-03-31 11:05:09,564 [trainer.py] => num_heads: 12
2024-03-31 11:05:09,564 [trainer.py] => total_sessions: 10
2024-03-31 11:05:09,564 [trainer.py] => seed: 0
2024-03-31 11:05:09,564 [trainer.py] => EPSILON: 1e-08
2024-03-31 11:05:09,564 [trainer.py] => init_epoch: 20
2024-03-31 11:05:09,564 [trainer.py] => optim: sgd
2024-03-31 11:05:09,564 [trainer.py] => epochs: 20
2024-03-31 11:05:09,564 [trainer.py] => fc_lrate: 0.01
2024-03-31 11:05:09,564 [trainer.py] => lrate: 0.001
2024-03-31 11:05:09,564 [trainer.py] => lrate_decay: 0.1
2024-03-31 11:05:09,564 [trainer.py] => batch_size: 128
2024-03-31 11:05:09,564 [trainer.py] => weight_decay: 0.001
2024-03-31 11:05:09,564 [trainer.py] => rank: 5
2024-03-31 11:05:09,564 [trainer.py] => lamb: 0.95
2024-03-31 11:05:09,564 [trainer.py] => lame: 1.0
2024-03-31 11:05:09,564 [trainer.py] => num_workers: 16
2024-03-31 11:05:11,157 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 11:05:14,311 [trainer.py] => All params: 109351451
2024-03-31 11:05:14,315 [trainer.py] => Trainable params: 109351451
2024-03-31 11:05:14,315 [inflora_ca1.py] => Learning on 0-10
2024-03-31 11:17:34,991 [inflora_ca1.py] => Task 0, Epoch 20/20 => Loss 0.102, Train_accy 96.42
2024-03-31 11:18:41,057 [trainer.py] => Time:806.7422122955322
2024-03-31 11:18:53,829 [trainer.py] => Time:12.771234035491943
2024-03-31 11:18:53,829 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 11:18:53,829 [trainer.py] => CNN: {'total': 99.3, '00-09': 99.3, 'old': 0, 'new': 99.3}
2024-03-31 11:18:53,829 [trainer.py] => CNN top1 curve: [99.3]
2024-03-31 11:18:53,829 [trainer.py] => CNN top1 with task curve: [99.3]
2024-03-31 11:18:53,829 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 11:18:53,831 [trainer.py] => All params: 109351451
2024-03-31 11:18:53,833 [trainer.py] => Trainable params: 99850
2024-03-31 11:18:53,833 [inflora_ca1.py] => Learning on 10-20
2024-03-31 11:29:25,908 [inflora_ca1.py] => Task 1, Epoch 20/20 => Loss 0.151, Train_accy 95.00
2024-03-31 11:30:15,321 [inflora_ca1.py] => CA Task 1 => Loss 0.048, Test_accy 97.350
2024-03-31 11:30:20,593 [inflora_ca1.py] => CA Task 1 => Loss 0.040, Test_accy 97.150
2024-03-31 11:30:25,906 [inflora_ca1.py] => CA Task 1 => Loss 0.037, Test_accy 97.600
2024-03-31 11:30:31,200 [inflora_ca1.py] => CA Task 1 => Loss 0.034, Test_accy 97.400
2024-03-31 11:30:36,546 [inflora_ca1.py] => CA Task 1 => Loss 0.034, Test_accy 97.450
2024-03-31 11:30:36,547 [trainer.py] => Time:702.7137093544006
2024-03-31 11:30:47,285 [trainer.py] => Time:10.738276958465576
2024-03-31 11:30:47,285 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 11:30:47,285 [trainer.py] => CNN: {'total': 97.45, '00-09': 97.8, '10-19': 97.1, 'old': 97.8, 'new': 97.1}
2024-03-31 11:30:47,285 [trainer.py] => CNN top1 curve: [99.3, 97.45]
2024-03-31 11:30:47,285 [trainer.py] => CNN top1 with task curve: [99.3, 99.2]
2024-03-31 11:30:47,285 [trainer.py] => CNN top1 task curve: [1.0, 0.9825]
2024-03-31 11:30:47,288 [trainer.py] => All params: 109351451
2024-03-31 11:30:47,289 [trainer.py] => Trainable params: 107540
2024-03-31 11:30:47,290 [inflora_ca1.py] => Learning on 20-30
2024-03-31 11:41:03,262 [inflora_ca1.py] => Task 2, Epoch 20/20 => Loss 0.118, Train_accy 96.22
2024-03-31 11:42:46,601 [inflora_ca1.py] => CA Task 2 => Loss 0.048, Test_accy 95.830
2024-03-31 11:43:00,115 [inflora_ca1.py] => CA Task 2 => Loss 0.043, Test_accy 95.970
2024-03-31 11:43:11,359 [inflora_ca1.py] => CA Task 2 => Loss 0.040, Test_accy 96.130
2024-03-31 11:43:24,905 [inflora_ca1.py] => CA Task 2 => Loss 0.036, Test_accy 96.130
2024-03-31 11:43:37,457 [inflora_ca1.py] => CA Task 2 => Loss 0.032, Test_accy 96.100
2024-03-31 11:43:37,457 [trainer.py] => Time:770.1675963401794
2024-03-31 11:44:05,281 [trainer.py] => Time:27.823511600494385
2024-03-31 11:44:05,281 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 11:44:05,281 [trainer.py] => CNN: {'total': 96.1, '00-09': 97.0, '10-19': 96.3, '20-29': 95.0, 'old': 96.65, 'new': 95.0}
2024-03-31 11:44:05,281 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1]
2024-03-31 11:44:05,281 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87]
2024-03-31 11:44:05,281 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334]
2024-03-31 11:44:05,283 [trainer.py] => All params: 109351451
2024-03-31 11:44:05,285 [trainer.py] => Trainable params: 115230
2024-03-31 11:44:05,285 [inflora_ca1.py] => Learning on 30-40
2024-03-31 11:55:51,347 [inflora_ca1.py] => Task 3, Epoch 20/20 => Loss 0.135, Train_accy 96.02
2024-03-31 11:56:44,076 [inflora_ca1.py] => CA Task 3 => Loss 0.054, Test_accy 95.250
2024-03-31 11:56:53,184 [inflora_ca1.py] => CA Task 3 => Loss 0.054, Test_accy 95.380
2024-03-31 11:57:02,330 [inflora_ca1.py] => CA Task 3 => Loss 0.048, Test_accy 95.550
2024-03-31 11:57:11,488 [inflora_ca1.py] => CA Task 3 => Loss 0.046, Test_accy 95.520
2024-03-31 11:57:20,696 [inflora_ca1.py] => CA Task 3 => Loss 0.047, Test_accy 95.600
2024-03-31 11:57:20,697 [trainer.py] => Time:795.4113011360168
2024-03-31 11:57:38,818 [trainer.py] => Time:18.121500492095947
2024-03-31 11:57:38,819 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 11:57:38,819 [trainer.py] => CNN: {'total': 95.6, '00-09': 96.6, '10-19': 94.8, '20-29': 95.0, '30-39': 96.0, 'old': 95.47, 'new': 96.0}
2024-03-31 11:57:38,819 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6]
2024-03-31 11:57:38,819 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88]
2024-03-31 11:57:38,819 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615]
2024-03-31 11:57:38,821 [trainer.py] => All params: 109351451
2024-03-31 11:57:38,822 [trainer.py] => Trainable params: 122920
2024-03-31 11:57:38,822 [inflora_ca1.py] => Learning on 40-50
2024-03-31 12:09:05,182 [inflora_ca1.py] => Task 4, Epoch 20/20 => Loss 0.130, Train_accy 96.12
2024-03-31 12:10:35,145 [inflora_ca1.py] => CA Task 4 => Loss 0.063, Test_accy 94.280
2024-03-31 12:10:55,852 [inflora_ca1.py] => CA Task 4 => Loss 0.054, Test_accy 94.320
2024-03-31 12:11:17,797 [inflora_ca1.py] => CA Task 4 => Loss 0.053, Test_accy 94.380
2024-03-31 12:11:38,755 [inflora_ca1.py] => CA Task 4 => Loss 0.050, Test_accy 94.440
2024-03-31 12:11:59,855 [inflora_ca1.py] => CA Task 4 => Loss 0.051, Test_accy 94.400
2024-03-31 12:11:59,856 [trainer.py] => Time:861.033207654953
2024-03-31 12:12:42,763 [trainer.py] => Time:42.90754437446594
2024-03-31 12:12:42,763 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 12:12:42,764 [trainer.py] => CNN: {'total': 94.4, '00-09': 95.9, '10-19': 93.9, '20-29': 93.6, '30-39': 95.2, '40-49': 93.4, 'old': 94.65, 'new': 93.4}
2024-03-31 12:12:42,764 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6, 94.4]
2024-03-31 12:12:42,764 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88, 98.78]
2024-03-31 12:12:42,764 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615, 0.9502]
2024-03-31 12:12:42,766 [trainer.py] => All params: 109351451
2024-03-31 12:12:42,767 [trainer.py] => Trainable params: 130610
2024-03-31 12:12:42,768 [inflora_ca1.py] => Learning on 50-60
2024-03-31 12:25:44,010 [inflora_ca1.py] => Task 5, Epoch 20/20 => Loss 0.152, Train_accy 94.52
2024-03-31 12:27:17,319 [inflora_ca1.py] => CA Task 5 => Loss 0.081, Test_accy 92.700
2024-03-31 12:27:40,881 [inflora_ca1.py] => CA Task 5 => Loss 0.066, Test_accy 93.250
2024-03-31 12:28:04,635 [inflora_ca1.py] => CA Task 5 => Loss 0.062, Test_accy 93.230
2024-03-31 12:28:28,515 [inflora_ca1.py] => CA Task 5 => Loss 0.061, Test_accy 93.420
2024-03-31 12:28:52,206 [inflora_ca1.py] => CA Task 5 => Loss 0.061, Test_accy 93.420
2024-03-31 12:28:52,207 [trainer.py] => Time:969.4392380714417
2024-03-31 12:29:43,440 [trainer.py] => Time:51.2332558631897
2024-03-31 12:29:43,440 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 12:29:43,440 [trainer.py] => CNN: {'total': 93.42, '00-09': 95.3, '10-19': 93.5, '20-29': 93.5, '30-39': 94.3, '40-49': 91.6, '50-59': 92.3, 'old': 93.64, 'new': 92.3}
2024-03-31 12:29:43,440 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6, 94.4, 93.42]
2024-03-31 12:29:43,440 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88, 98.78, 98.72]
2024-03-31 12:29:43,441 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615, 0.9502, 0.9398333333333333]
2024-03-31 12:29:43,442 [trainer.py] => All params: 109351451
2024-03-31 12:29:43,444 [trainer.py] => Trainable params: 138300
2024-03-31 12:29:43,444 [inflora_ca1.py] => Learning on 60-70
2024-03-31 12:42:31,940 [inflora_ca1.py] => Task 6, Epoch 20/20 => Loss 0.150, Train_accy 94.92
2024-03-31 12:44:07,413 [inflora_ca1.py] => CA Task 6 => Loss 0.069, Test_accy 92.360
2024-03-31 12:44:34,281 [inflora_ca1.py] => CA Task 6 => Loss 0.066, Test_accy 92.460
2024-03-31 12:44:59,647 [inflora_ca1.py] => CA Task 6 => Loss 0.064, Test_accy 92.500
2024-03-31 12:45:26,922 [inflora_ca1.py] => CA Task 6 => Loss 0.057, Test_accy 92.610
2024-03-31 12:45:53,129 [inflora_ca1.py] => CA Task 6 => Loss 0.062, Test_accy 92.630
2024-03-31 12:45:53,130 [trainer.py] => Time:969.6854372024536
2024-03-31 12:46:49,963 [trainer.py] => Time:56.833657026290894
2024-03-31 12:46:49,964 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 12:46:49,964 [trainer.py] => CNN: {'total': 92.63, '00-09': 94.4, '10-19': 92.4, '20-29': 92.4, '30-39': 94.2, '40-49': 91.6, '50-59': 92.3, '60-69': 91.1, 'old': 92.88, 'new': 91.1}
2024-03-31 12:46:49,964 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6, 94.4, 93.42, 92.63]
2024-03-31 12:46:49,964 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88, 98.78, 98.72, 98.64]
2024-03-31 12:46:49,964 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615, 0.9502, 0.9398333333333333, 0.9324285714285714]
2024-03-31 12:46:49,966 [trainer.py] => All params: 109351451
2024-03-31 12:46:49,968 [trainer.py] => Trainable params: 145990
2024-03-31 12:46:49,968 [inflora_ca1.py] => Learning on 70-80
2024-03-31 12:59:03,106 [inflora_ca1.py] => Task 7, Epoch 20/20 => Loss 0.145, Train_accy 95.20
2024-03-31 13:00:39,508 [inflora_ca1.py] => CA Task 7 => Loss 0.071, Test_accy 91.840
2024-03-31 13:01:09,385 [inflora_ca1.py] => CA Task 7 => Loss 0.068, Test_accy 92.080
2024-03-31 13:01:39,560 [inflora_ca1.py] => CA Task 7 => Loss 0.063, Test_accy 92.140
2024-03-31 13:02:10,561 [inflora_ca1.py] => CA Task 7 => Loss 0.062, Test_accy 92.200
2024-03-31 13:02:39,950 [inflora_ca1.py] => CA Task 7 => Loss 0.065, Test_accy 92.180
2024-03-31 13:02:39,951 [trainer.py] => Time:949.9829230308533
2024-03-31 13:03:50,290 [trainer.py] => Time:70.33866119384766
2024-03-31 13:03:50,290 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 13:03:50,290 [trainer.py] => CNN: {'total': 92.18, '00-09': 94.4, '10-19': 91.9, '20-29': 91.0, '30-39': 93.7, '40-49': 91.8, '50-59': 90.6, '60-69': 90.8, '70-79': 93.2, 'old': 92.03, 'new': 93.2}
2024-03-31 13:03:50,290 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6, 94.4, 93.42, 92.63, 92.18]
2024-03-31 13:03:50,290 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88, 98.78, 98.72, 98.64, 98.64]
2024-03-31 13:03:50,290 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615, 0.9502, 0.9398333333333333, 0.9324285714285714, 0.927]
2024-03-31 13:03:50,292 [trainer.py] => All params: 109351451
2024-03-31 13:03:50,294 [trainer.py] => Trainable params: 153680
2024-03-31 13:03:50,294 [inflora_ca1.py] => Learning on 80-90
2024-03-31 13:17:07,804 [inflora_ca1.py] => Task 8, Epoch 20/20 => Loss 0.130, Train_accy 95.50
2024-03-31 13:18:56,170 [inflora_ca1.py] => CA Task 8 => Loss 0.069, Test_accy 91.980
2024-03-31 13:19:26,666 [inflora_ca1.py] => CA Task 8 => Loss 0.062, Test_accy 92.120
2024-03-31 13:19:55,567 [inflora_ca1.py] => CA Task 8 => Loss 0.061, Test_accy 92.240
2024-03-31 13:20:25,510 [inflora_ca1.py] => CA Task 8 => Loss 0.056, Test_accy 92.320
2024-03-31 13:20:55,294 [inflora_ca1.py] => CA Task 8 => Loss 0.056, Test_accy 92.370
2024-03-31 13:20:55,294 [trainer.py] => Time:1025.0002522468567
2024-03-31 13:22:06,625 [trainer.py] => Time:71.33044195175171
2024-03-31 13:22:06,625 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 13:22:06,625 [trainer.py] => CNN: {'total': 92.37, '00-09': 94.3, '10-19': 90.9, '20-29': 91.1, '30-39': 92.6, '40-49': 91.9, '50-59': 91.0, '60-69': 90.6, '70-79': 93.4, '80-89': 95.5, 'old': 91.98, 'new': 95.5}
2024-03-31 13:22:06,625 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6, 94.4, 93.42, 92.63, 92.18, 92.37]
2024-03-31 13:22:06,625 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88, 98.78, 98.72, 98.64, 98.64, 98.66]
2024-03-31 13:22:06,625 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615, 0.9502, 0.9398333333333333, 0.9324285714285714, 0.927, 0.929]
2024-03-31 13:22:06,627 [trainer.py] => All params: 109351451
2024-03-31 13:22:06,629 [trainer.py] => Trainable params: 161370
2024-03-31 13:22:06,629 [inflora_ca1.py] => Learning on 90-100
2024-03-31 13:35:38,748 [inflora_ca1.py] => Task 9, Epoch 20/20 => Loss 0.104, Train_accy 96.80
2024-03-31 13:37:33,652 [inflora_ca1.py] => CA Task 9 => Loss 0.081, Test_accy 91.460
2024-03-31 13:38:12,002 [inflora_ca1.py] => CA Task 9 => Loss 0.071, Test_accy 91.480
2024-03-31 13:38:50,277 [inflora_ca1.py] => CA Task 9 => Loss 0.066, Test_accy 91.600
2024-03-31 13:39:29,691 [inflora_ca1.py] => CA Task 9 => Loss 0.063, Test_accy 91.640
2024-03-31 13:40:07,980 [inflora_ca1.py] => CA Task 9 => Loss 0.061, Test_accy 91.660
2024-03-31 13:40:07,981 [trainer.py] => Time:1081.3517401218414
2024-03-31 13:41:22,491 [trainer.py] => Time:74.50984740257263
2024-03-31 13:41:22,491 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 13:41:22,491 [trainer.py] => CNN: {'total': 91.66, '00-09': 93.0, '10-19': 91.2, '20-29': 91.0, '30-39': 90.9, '40-49': 89.7, '50-59': 90.8, '60-69': 90.9, '70-79': 92.9, '80-89': 94.5, '90-99': 91.7, 'old': 91.66, 'new': 91.7}
2024-03-31 13:41:22,491 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6, 94.4, 93.42, 92.63, 92.18, 92.37, 91.66]
2024-03-31 13:41:22,491 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88, 98.78, 98.72, 98.64, 98.64, 98.66, 98.78]
2024-03-31 13:41:22,491 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615, 0.9502, 0.9398333333333333, 0.9324285714285714, 0.927, 0.929, 0.9212]
2024-03-31 19:08:04,714 [trainer.py] => config: configs/cifar100_infloraca.json
2024-03-31 19:08:04,715 [trainer.py] => device: [device(type='cuda', index=2)]
2024-03-31 19:08:04,715 [trainer.py] => prefix: reproduce
2024-03-31 19:08:04,715 [trainer.py] => dataset: cifar100
2024-03-31 19:08:04,715 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 19:08:04,715 [trainer.py] => memory_size: 0
2024-03-31 19:08:04,715 [trainer.py] => memory_per_class: 0
2024-03-31 19:08:04,715 [trainer.py] => fixed_memory: True
2024-03-31 19:08:04,715 [trainer.py] => shuffle: False
2024-03-31 19:08:04,715 [trainer.py] => init_cls: 10
2024-03-31 19:08:04,715 [trainer.py] => increment: 10
2024-03-31 19:08:04,715 [trainer.py] => model_name: InfLoRA_CA1
2024-03-31 19:08:04,715 [trainer.py] => net_type: sip
2024-03-31 19:08:04,715 [trainer.py] => embd_dim: 768
2024-03-31 19:08:04,715 [trainer.py] => num_heads: 12
2024-03-31 19:08:04,715 [trainer.py] => total_sessions: 10
2024-03-31 19:08:04,715 [trainer.py] => seed: 0
2024-03-31 19:08:04,715 [trainer.py] => EPSILON: 1e-08
2024-03-31 19:08:04,715 [trainer.py] => init_epoch: 20
2024-03-31 19:08:04,715 [trainer.py] => optim: sgd
2024-03-31 19:08:04,715 [trainer.py] => epochs: 20
2024-03-31 19:08:04,715 [trainer.py] => fc_lrate: 0.01
2024-03-31 19:08:04,715 [trainer.py] => lrate: 0.001
2024-03-31 19:08:04,715 [trainer.py] => lrate_decay: 0.1
2024-03-31 19:08:04,715 [trainer.py] => batch_size: 128
2024-03-31 19:08:04,715 [trainer.py] => weight_decay: 0.001
2024-03-31 19:08:04,715 [trainer.py] => rank: 5
2024-03-31 19:08:04,715 [trainer.py] => lamb: 0.95
2024-03-31 19:08:04,715 [trainer.py] => lame: 1.0
2024-03-31 19:08:04,715 [trainer.py] => num_workers: 16
2024-03-31 19:08:11,064 [trainer.py] => config: configs/cifar100_infloraca.json
2024-03-31 19:08:11,064 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 19:08:11,064 [trainer.py] => prefix: reproduce
2024-03-31 19:08:11,064 [trainer.py] => dataset: cifar100
2024-03-31 19:08:11,064 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 19:08:11,064 [trainer.py] => memory_size: 0
2024-03-31 19:08:11,064 [trainer.py] => memory_per_class: 0
2024-03-31 19:08:11,064 [trainer.py] => fixed_memory: True
2024-03-31 19:08:11,064 [trainer.py] => shuffle: False
2024-03-31 19:08:11,064 [trainer.py] => init_cls: 10
2024-03-31 19:08:11,065 [trainer.py] => increment: 10
2024-03-31 19:08:11,065 [trainer.py] => model_name: InfLoRA_CA1
2024-03-31 19:08:11,065 [trainer.py] => net_type: sip
2024-03-31 19:08:11,065 [trainer.py] => embd_dim: 768
2024-03-31 19:08:11,065 [trainer.py] => num_heads: 12
2024-03-31 19:08:11,065 [trainer.py] => total_sessions: 10
2024-03-31 19:08:11,065 [trainer.py] => seed: 0
2024-03-31 19:08:11,065 [trainer.py] => EPSILON: 1e-08
2024-03-31 19:08:11,065 [trainer.py] => init_epoch: 20
2024-03-31 19:08:11,065 [trainer.py] => optim: sgd
2024-03-31 19:08:11,065 [trainer.py] => epochs: 20
2024-03-31 19:08:11,065 [trainer.py] => fc_lrate: 0.01
2024-03-31 19:08:11,065 [trainer.py] => lrate: 0.001
2024-03-31 19:08:11,065 [trainer.py] => lrate_decay: 0.1
2024-03-31 19:08:11,065 [trainer.py] => batch_size: 128
2024-03-31 19:08:11,065 [trainer.py] => weight_decay: 0.001
2024-03-31 19:08:11,065 [trainer.py] => rank: 5
2024-03-31 19:08:11,065 [trainer.py] => lamb: 0.95
2024-03-31 19:08:11,065 [trainer.py] => lame: 1.0
2024-03-31 19:08:11,065 [trainer.py] => num_workers: 16
2024-03-31 19:08:12,580 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 19:08:16,050 [trainer.py] => All params: 109351451
2024-03-31 19:08:16,053 [trainer.py] => Trainable params: 109351451
2024-03-31 19:08:16,053 [inflora_ca1.py] => Learning on 0-10
2024-03-31 19:08:45,173 [trainer.py] => config: configs/cifar100_infloraca.json
2024-03-31 19:08:45,173 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 19:08:45,173 [trainer.py] => prefix: reproduce
2024-03-31 19:08:45,173 [trainer.py] => dataset: cifar100
2024-03-31 19:08:45,173 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 19:08:45,173 [trainer.py] => memory_size: 0
2024-03-31 19:08:45,173 [trainer.py] => memory_per_class: 0
2024-03-31 19:08:45,173 [trainer.py] => fixed_memory: True
2024-03-31 19:08:45,173 [trainer.py] => shuffle: False
2024-03-31 19:08:45,173 [trainer.py] => init_cls: 10
2024-03-31 19:08:45,173 [trainer.py] => increment: 10
2024-03-31 19:08:45,174 [trainer.py] => model_name: InfLoRA_CA1
2024-03-31 19:08:45,174 [trainer.py] => net_type: sip
2024-03-31 19:08:45,174 [trainer.py] => embd_dim: 768
2024-03-31 19:08:45,174 [trainer.py] => num_heads: 12
2024-03-31 19:08:45,174 [trainer.py] => total_sessions: 10
2024-03-31 19:08:45,174 [trainer.py] => seed: 0
2024-03-31 19:08:45,174 [trainer.py] => EPSILON: 1e-08
2024-03-31 19:08:45,174 [trainer.py] => init_epoch: 20
2024-03-31 19:08:45,174 [trainer.py] => optim: sgd
2024-03-31 19:08:45,174 [trainer.py] => epochs: 20
2024-03-31 19:08:45,174 [trainer.py] => fc_lrate: 0.01
2024-03-31 19:08:45,174 [trainer.py] => lrate: 0.001
2024-03-31 19:08:45,174 [trainer.py] => lrate_decay: 0.1
2024-03-31 19:08:45,174 [trainer.py] => batch_size: 128
2024-03-31 19:08:45,174 [trainer.py] => weight_decay: 0.001
2024-03-31 19:08:45,174 [trainer.py] => rank: 5
2024-03-31 19:08:45,174 [trainer.py] => lamb: 0.95
2024-03-31 19:08:45,174 [trainer.py] => lame: 1.0
2024-03-31 19:08:45,174 [trainer.py] => num_workers: 16
2024-03-31 19:08:46,804 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 19:08:49,368 [trainer.py] => All params: 109351451
2024-03-31 19:08:49,370 [trainer.py] => Trainable params: 109351451
2024-03-31 19:08:49,371 [inflora_ca1.py] => Learning on 0-10
2024-03-31 19:21:58,633 [inflora_ca1.py] => Task 0, Epoch 20/20 => Loss 0.102, Train_accy 96.42
2024-03-31 19:23:18,827 [trainer.py] => Time:869.4568948745728
2024-03-31 19:23:32,359 [trainer.py] => Time:13.53152871131897
2024-03-31 19:23:32,360 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 19:23:32,360 [trainer.py] => CNN: {'total': 99.3, '00-09': 99.3, 'old': 0, 'new': 99.3}
2024-03-31 19:23:32,360 [trainer.py] => CNN top1 curve: [99.3]
2024-03-31 19:23:32,360 [trainer.py] => CNN top1 with task curve: [99.3]
2024-03-31 19:23:32,360 [trainer.py] => CNN top1 task curve: [1.0]
2024-03-31 19:23:32,364 [trainer.py] => All params: 109351451
2024-03-31 19:23:32,366 [trainer.py] => Trainable params: 99850
2024-03-31 19:23:32,366 [inflora_ca1.py] => Learning on 10-20
2024-03-31 19:36:25,266 [inflora_ca1.py] => Task 1, Epoch 20/20 => Loss 0.151, Train_accy 95.00
2024-03-31 19:37:40,284 [inflora_ca1.py] => CA Task 1 => Loss 0.048, Test_accy 97.350
2024-03-31 19:37:49,383 [inflora_ca1.py] => CA Task 1 => Loss 0.040, Test_accy 97.150
2024-03-31 19:37:58,743 [inflora_ca1.py] => CA Task 1 => Loss 0.037, Test_accy 97.600
2024-03-31 19:38:07,670 [inflora_ca1.py] => CA Task 1 => Loss 0.034, Test_accy 97.400
2024-03-31 19:38:17,099 [inflora_ca1.py] => CA Task 1 => Loss 0.034, Test_accy 97.450
2024-03-31 19:38:17,099 [trainer.py] => Time:884.7331681251526
2024-03-31 19:38:34,955 [trainer.py] => Time:17.856444120407104
2024-03-31 19:38:34,956 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 19:38:34,956 [trainer.py] => CNN: {'total': 97.45, '00-09': 97.8, '10-19': 97.1, 'old': 97.8, 'new': 97.1}
2024-03-31 19:38:34,956 [trainer.py] => CNN top1 curve: [99.3, 97.45]
2024-03-31 19:38:34,956 [trainer.py] => CNN top1 with task curve: [99.3, 99.2]
2024-03-31 19:38:34,956 [trainer.py] => CNN top1 task curve: [1.0, 0.9825]
2024-03-31 19:38:34,959 [trainer.py] => All params: 109351451
2024-03-31 19:38:34,961 [trainer.py] => Trainable params: 107540
2024-03-31 19:38:34,961 [inflora_ca1.py] => Learning on 20-30
2024-03-31 19:51:16,397 [inflora_ca1.py] => Task 2, Epoch 20/20 => Loss 0.118, Train_accy 96.22
2024-03-31 19:52:30,239 [inflora_ca1.py] => CA Task 2 => Loss 0.048, Test_accy 95.830
2024-03-31 19:52:42,797 [inflora_ca1.py] => CA Task 2 => Loss 0.043, Test_accy 95.970
2024-03-31 19:52:54,360 [inflora_ca1.py] => CA Task 2 => Loss 0.040, Test_accy 96.130
2024-03-31 19:53:05,681 [inflora_ca1.py] => CA Task 2 => Loss 0.036, Test_accy 96.130
2024-03-31 19:53:17,195 [inflora_ca1.py] => CA Task 2 => Loss 0.032, Test_accy 96.100
2024-03-31 19:53:17,195 [trainer.py] => Time:882.2337698936462
2024-03-31 19:53:42,599 [trainer.py] => Time:25.403493404388428
2024-03-31 19:53:42,599 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 19:53:42,599 [trainer.py] => CNN: {'total': 96.1, '00-09': 97.0, '10-19': 96.3, '20-29': 95.0, 'old': 96.65, 'new': 95.0}
2024-03-31 19:53:42,599 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1]
2024-03-31 19:53:42,599 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87]
2024-03-31 19:53:42,599 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334]
2024-03-31 19:53:42,601 [trainer.py] => All params: 109351451
2024-03-31 19:53:42,603 [trainer.py] => Trainable params: 115230
2024-03-31 19:53:42,603 [inflora_ca1.py] => Learning on 30-40
2024-03-31 20:06:06,687 [inflora_ca1.py] => Task 3, Epoch 20/20 => Loss 0.135, Train_accy 96.02
2024-03-31 20:07:20,577 [inflora_ca1.py] => CA Task 3 => Loss 0.054, Test_accy 95.250
2024-03-31 20:07:34,111 [inflora_ca1.py] => CA Task 3 => Loss 0.054, Test_accy 95.380
2024-03-31 20:07:50,385 [inflora_ca1.py] => CA Task 3 => Loss 0.048, Test_accy 95.550
2024-03-31 20:08:07,098 [inflora_ca1.py] => CA Task 3 => Loss 0.046, Test_accy 95.520
2024-03-31 20:08:22,122 [inflora_ca1.py] => CA Task 3 => Loss 0.047, Test_accy 95.600
2024-03-31 20:08:22,122 [trainer.py] => Time:879.5191059112549
2024-03-31 20:08:58,090 [trainer.py] => Time:35.967758655548096
2024-03-31 20:08:58,090 [inflora_ca1.py] => Exemplar size: 0
2024-03-31 20:08:58,090 [trainer.py] => CNN: {'total': 95.6, '00-09': 96.6, '10-19': 94.8, '20-29': 95.0, '30-39': 96.0, 'old': 95.47, 'new': 96.0}
2024-03-31 20:08:58,090 [trainer.py] => CNN top1 curve: [99.3, 97.45, 96.1, 95.6]
2024-03-31 20:08:58,090 [trainer.py] => CNN top1 with task curve: [99.3, 99.2, 98.87, 98.88]
2024-03-31 20:08:58,090 [trainer.py] => CNN top1 task curve: [1.0, 0.9825, 0.9683333333333334, 0.9615]
2024-03-31 20:08:58,092 [trainer.py] => All params: 109351451
2024-03-31 20:08:58,094 [trainer.py] => Trainable params: 122920
2024-03-31 20:08:58,094 [inflora_ca1.py] => Learning on 40-50
2024-03-31 20:17:59,421 [trainer.py] => config: configs/cifar100_infloraca.json
2024-03-31 20:17:59,421 [trainer.py] => device: [device(type='cuda', index=1)]
2024-03-31 20:17:59,421 [trainer.py] => prefix: reproduce
2024-03-31 20:17:59,421 [trainer.py] => dataset: cifar100
2024-03-31 20:17:59,421 [trainer.py] => data_path: /home/liangys/data/cifar100
2024-03-31 20:17:59,421 [trainer.py] => memory_size: 0
2024-03-31 20:17:59,421 [trainer.py] => memory_per_class: 0
2024-03-31 20:17:59,421 [trainer.py] => fixed_memory: True
2024-03-31 20:17:59,421 [trainer.py] => shuffle: False
2024-03-31 20:17:59,421 [trainer.py] => init_cls: 10
2024-03-31 20:17:59,421 [trainer.py] => increment: 10
2024-03-31 20:17:59,421 [trainer.py] => model_name: InfLoRA_CA1
2024-03-31 20:17:59,421 [trainer.py] => net_type: sip
2024-03-31 20:17:59,421 [trainer.py] => embd_dim: 768
2024-03-31 20:17:59,421 [trainer.py] => num_heads: 12
2024-03-31 20:17:59,421 [trainer.py] => total_sessions: 10
2024-03-31 20:17:59,421 [trainer.py] => seed: 0
2024-03-31 20:17:59,421 [trainer.py] => EPSILON: 1e-08
2024-03-31 20:17:59,421 [trainer.py] => init_epoch: 20
2024-03-31 20:17:59,421 [trainer.py] => optim: sgd
2024-03-31 20:17:59,421 [trainer.py] => epochs: 20
2024-03-31 20:17:59,421 [trainer.py] => fc_lrate: 0.01
2024-03-31 20:17:59,422 [trainer.py] => lrate: 0.001
2024-03-31 20:17:59,422 [trainer.py] => lrate_decay: 0.1
2024-03-31 20:17:59,422 [trainer.py] => batch_size: 128
2024-03-31 20:17:59,422 [trainer.py] => weight_decay: 0.001
2024-03-31 20:17:59,422 [trainer.py] => rank: 5
2024-03-31 20:17:59,422 [trainer.py] => lamb: 0.95
2024-03-31 20:17:59,422 [trainer.py] => lame: 1.0
2024-03-31 20:17:59,422 [trainer.py] => num_workers: 16
2024-03-31 20:18:01,023 [data_manager.py] => [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2024-03-31 20:18:04,498 [trainer.py] => All params: 109351451
2024-03-31 20:18:04,501 [trainer.py] => Trainable params: 109351451
2024-03-31 20:18:04,502 [inflora_ca1.py] => Learning on 0-10
